---
Pr-id: MoneyLab
P-id: INC Reader
A-id: 10
Type: article
Book-type: anthology
Anthology item: article
Item-id: unique no.
Article-title: title of the article
Article-status: accepted
Author: name(s) of author(s)
Author-email:   corresponding address
Author-bio:  about the author
Abstract:   short description of the article (100 words)
Keywords:   50 keywords for search and indexing
Rights: CC BY-NC 4.0
...


> **Digging into EU Data Laws and Their Impact on African
> Researchers**[^09chapter6_1]

*Paul Esselaar*

There is a well-known saying that when the United States (US) sneezes,
the rest of the world catches a cold. While this used to be true for
Africa, the European Union (EU) has become the single most important
market for African goods, with Africa exporting 33 per cent of its goods
to the EU and importing 31 per cent of its goods from the continent.^1^
In addition, the EU is the largest source of foreign direct investment
in South Africa,^2^ and legislative changes to the EU have an inevitable
and significant impact on African countries. This has been referred to
as the ‘Brussels effect’ and essentially shows how the EU effectively
exports norms and regulations to other countries. Anu Bradford^3^ sets
out three main preconditions for the Brussels effect, namely (*a*)
market size, (*b*) laws that are precise, comprehensive, available in
multiple languages, and easy to copy, and (*c*) flexible drafting which
allows the laws to work across different legal systems.

While the Brussels effect refers to the influence of Europe on other
countries, it has been particularly noticeable in the digital space,
where African countries have been in a flurry of activity to enact
legislation to protect personal data, most of which has been published
in the last 10 years.^4^ A good deal of the motivation for this has been
to harmonize their laws with the EU’s General Data Protection Regulation
(GDPR), 2016, to the extent that ‘of the 60 countries that have enacted
new data protection laws over the last decade, almost all modelled their
approach in full or in part on the GDPR’.^5^

The Brussels effect has influenced not only the laws the African
countries but also their regulators, and even court decisions have
followed the approach of the Court of Justice of the EU.^6^ Regional
organizations such as the Economic Community of West African States
(WAEMU) and the Common Market for Easter and Southern Africa (COMESA)
have also been modelled on the EU, to such an extent that the Court of
Justice for WAEMU ruled that the Treaty of Dakar (which established
WAEMU) should be interpreted with reference to the Treaty of Rome (which
founded the European Community and the jurisprudence of the Court of
Justice of the EU).^7^

The Brussels effect refers not only to the *de jure* influence of
Europe, but also a *de facto* influence. An example of this effect is
African farmers’ food safety practices which are largely determined by
the EU.^8^ Another example was the EU decision to prevent the South
African company De Beers from buying rough diamonds from the Russian
company Alrosa^9^ – effectively resulting in an international
prohibition even though neither company was located in Europe. Indeed,
if an international merger is prohibited in the EU, then it is
effectively banned worldwide, even if it is deemed acceptable by
regulators in other jurisdictions.^10^ In short, when the EU changes its
laws relating to data, there is a good chance that African countries
will be forced to follow suit sooner or later.

Bearing in mind the Brussels effect, the remainder of this chapter
considers the recent developments in the regulation of data by the EU.
The chapter concludes with a call on the EU to expand the scope of its
impact assessment to include countries outside of it and, in so doing,
acknowledge the de facto and de jure Brussels effect on African
researchers.

# The EU Strategy for Data

In 2020, the European Commission released a European strategy for
data^11^ in which it outlined its vision for the regulation of data. The
strategy referenced existing legislation – such as the regulation of the
free flow of non-personal data (FFD)^12^ which focuses on preventing EU
members from implementing data localization – and outlined a strategy to
create a single European market for data, which would hold not only data
from the EU but also from around the world and include personal data,
non-personal data, and sensitive business data, including high-quality
product data.^13^ In particular, the strategy focused on the flow of
data and the incorporation of European values, particularly personal
data protection, consumer protection, and competition law.

The strategy further noted that ‘sensitive data (e.g. health data) in
public databases is often not made available for research purposes, in
the absence of capacity of mechanisms that allow specific research
actions to be taken in a manner compliant with personal data protection
rules’.^14^ The European Open Science Cloud is an example of an
initiative that provides access to *European* researchers; the creation
of the common European Health Data Space^15^ aims to assist with
preventing, detecting, and curing diseases, as well as allowing for
informed, evidence-based decisions to improve the accessibility,
effectiveness, and sustainability of healthcare systems.

Although there are many observations to make on the EU strategy for
Data, there are two aspects to highlight for our purposes: (*a*) data
needs to be managed in a holistic manner, taking into consideration
consumer protection, competition law, and so on – not just from a data
protection or privacy perspective, and (*b*) the EU is open to receiving
data from around the world but is less focused on providing access to
the data for non-European researchers.

## Putting the EU Strategy for Data into Law

Since the publication of the EU strategy for Data, there have been
several EU laws focusing on data regulation that have been published,
namely the Digital Services Act (DSA), 2022;^16^ the Digital Markets Act
(DMA), 2022;^17^ and the recent Artificial Intelligence Act (AIA),
2024,^18^ as well as the Data Act (DA), 2023^19^ (collectively referred
to as the EU data laws). Each of these Acts is discussed briefly in
order to contextualize the EU’s holistic approach to data regulation.

At a high level, the *DSA* seeks to manage illegal content, ensure
advertising is transparent, and combat disinformation in large (over 45
million users) platforms,^20^ which are designated as very large online
platforms (VLOPs) and very large online search engines (VLOSEs). It does
this by placing obligations on social media platforms and search engines
to address illegal content, disclose how their algorithms work to the
regulators, and provide transparency on how decisions are made to remove
content and how advertisers target users. It was fully implemented in
2024. In short, the Act is focused on expanding consumer rights with
regard to digital services.

The *DMA* is a sister piece of legislation that aims at preventing large
companies (gatekeepers^21^) from abusing their market power by
preventing self-preferencing (providing prominence to its own products),
reuse of personal data, providing business rights to smaller companies,
prohibiting contractual requirements to offer the best deals exclusively
on the companies’ platform, preserving device neutrality (where
pre-installed applications can be deleted), and prohibiting the bundling
of products. In short, the DMA is focused on encouraging competition in
digital markets.

The *AIA*^22^ is a relatively groundbreaking piece of legislation and
seeks not only to articulate the principles of artificial intelligence
(AI) regulation but also to amend various other EU laws to bring them in
line with the AIA. The AIA creates and defines ‘high-risk’ AI
systems,^23^ provides standards for risk management^24^ and data
governance,^25^ and, interestingly, explicitly mandates the use of human
oversight, including the ability to stop the AI using ‘a “stop”
button’.^26^ The AIA also requires that each EU member country have a
notifying authority,^27^ national supervisory authority,^28^ and market
surveillance authority^29^ to monitor and manage AI use. Generative
content created by AI systems – including so-called deepfakes – must be
labelled, and summaries of the data used to train the AI must be
provided to users.^30^

Finally, the *DA*^31^ is designed to regulate the Internet of Things
(IoT). It aims to do the following:

*Facilitate access to data* by consumers and businesses by creating
legal certainty as to when data can be requested or must be provided, as
well as setting out contractual rules for sharing of data.

*Force businesses to provide data to public bodies*, primarily in
emergency situations, but also when business to government data sharing
is justified.

*Facilitate switching between cloud and edge services*, where cloud
(typically with a central data centre) can send data to the ‘edge’
(typically outside of a data centre) which is closer to the user who is
able to collect data.

*Control access to data by non-EU countries* in order to enhance trust
in the EU data economy.

*Develop interoperability standards to make it easier to move services
between service providers* which would include smart contracts that
could be based on predetermined conditions set up by the user.

*Integrate the DA with other EU legislation*, particularly the GDPR, and
respect the confidentiality of all data in equipment used by the user
(terminal equipment).^32^

These EU data laws are the natural progression of the EU strategy for
data and illustrate a holistic approach to managing data, rather than
focusing exclusively on personal data. At a fundamental level, these EU
data laws rely on data categorization in order to regulate the operation
of data, and it is to how data is categorized that we now turn.

# One Concept to Rule them All: Data Categorization

A careful look at the legislation governing data reveals that each of
the EU Acts governing data relies on data categorization. For example,
the GDPR only governs ‘personal data’, and any data that is not
considered to be ‘personal’ is outside the scope of the GDPR. Similarly,
the DA manages ‘product data’ which is generated from ‘connected
products’ linked to the internet (IoT). Since the correct categorization
of data is so fundamental to the operation of the legislation, it is
critical that the distinction between the different types of data is
clear and unambiguous. In the section that follows, some of the problems
with data categorization are highlighted, and in the subsequent section
its knock-on impact is discussed.

Beginning with the distinction between ‘personal data’ and ‘non-personal
data’, this concept has seen some significant sea changes in the EU,
which is surprising, considering how entrenched the concept of personal
data was thought to be. One particular development occurred on 26 April
2023 in the case of *Single Resolution Board v. European Data Protection
Supervisor* in the General Court (Eighth Chamber, Extended
Composition)^33^ Pwhere the court was required to provide guidance on
whether pseudonymized data was ‘data’ or ‘personal data’. Up until this
case, it was considered to be settled law that ‘pseudonymized data’ was
always ‘personal data’.^34^

In this matter, a central resolution authority within the banking union
in Europe provided data to Deloitte. The information was pseudonymized
by means of a unique and randomized 33-digit alphanumeric code which was
assigned to each record. It was later discovered by some of the data
subjects who submitted personal data to the Single Resolution Board
(SRB) that their data had been provided to Deloitte, and they duly laid
complaints with the European Data Protection Supervisor (EDPS) that the
SRB had breached its duties in terms of Article 15 of Regulation
2018/1725^35^ by failing to indicate that it was providing personal data
to third parties in its privacy statement. The SRB refuted this
complaint and argued that, in the hands of Deloitte, the data was not
personal data as the company had no reasonable prospect of
re-identifying the data.

In upholding the SRB’s position against the EDPS, the court indicated
that in the hands of Deloitte, the data was not personal data, and so
there was no obligation of the SRB to disclose the sharing of the data
with Deloitte. Specifically, the court referred to the test as set out
in Recital 16 of Regulation 2018/1725 which indicates that all objective
factors, including (but not limited to) (*a*) cost of reidentifying,
(*b*) amount of time required to reidentify, (*c*) available technology
at time, and (*d*) expected technological developments, should be
considered when determining whether the information is ‘data’ or
‘personal data’. The court also endorsed the approach of *Breyer v.
Bundesrepublik Deutschland*, 19 October 2016, Case C-582/14, that
re-identification was not reasonably possible if ‘the identification of
the data subject was prohibited by law or practically impossible on
account of the fact that it requires a disproportionate effort in terms
of time, cost and man-power, so that the risk of identification appears
in reality to be insignificant.’^36^

The SRB case is a critical watershed in data protection law in that it
provides some assistance in how personal data could be differentiated
from non-personal data. In particular, the following points are worth
emphasizing: (*a*) the test was to determine whether the data was
subjective (that is, in the hands of Deloitte) rather than approached
from the perspective of a reasonably competent and objective third
party, and (*b*) the lack of a ‘legal’ manner to re-identify the data
would result in the data being considered to be de-identified.

The SRB case has since been appealed by the European Data Protection
Board (EDPB) on the grounds that the court misdirected itself when it
required that the EDPB assess whether the data was personal or not,
misinterpreted whether pseudonymized data was personal or not, and
placed the onus on the EDPS to prove that the SRB had effectively
anonymized the data it was processing.^37^

While the definitive text on personal data is the GDPR, it could be
argued that the DA should be confined to non-personal data or ‘product
data’. While this seems to be mostly the intention, the DA itself does
not do this and deals with both personal data and non-personal data
which emanates from ‘connected products’.^38^ The definition of
‘connected product’ in Article 2(5) is clearly a critical definition on
which the DA hinges and is defined thus:

> … an item that obtains, generates or collects data concerning its use
> or environment and that is able to communicate product data via an
> electronic communications service, physical connection or on-device
> access, and whose primary function is not the storing, processing or
> transmission of data on behalf of any party other than the user.^39^

From this definition, it is possible to extrapolate that ‘product data’
is data which (*a*) emanates from a product, (*b*) is about the product
itself or its use in its environment, (*c*) is communicated via the
internet, and (*d*) excludes data from, for instance, telecommunications
platforms and server farms.

Logically, this definition also means that the DA creates a distinction
between ‘product data’ and ‘non-product data’, which some commentators
have described as both artificial and confusing.^40^ This is not the end
of the difficulties as there is now a new category of ‘exportable data’,
which refers to input and output data (including data which is
co-generated by the customer and the data holder) but excludes data
which is protected by intellectual property rights or constitutes a
trade secret.^41^ Two further new definitions are introduced of ‘related
service data’: (*a*) data generated by the use of the product and (*b*)
‘readily available data’ which refers to data which can obtained without
disproportionate effort.^42^

On a practical level, these definitions demand that data holders –
holders of product data – need to undertake a significant amount of work
to restructure their underlying framework for data in order to place it
into the various categories as required by the DA. An example of these
‘categories’ which a data holder would be required to implement would be
(*a*) product data (data generated by the use of the product)^43^ which
is personal, (*b*) product data which is personal and exportable, (*c*)
product data which is personal and readily available, (*d*) non-product
data which is personal, (*e*) non-product data which is personal and
exportable, and (*f*) non-product data which is personal and readily
available. (The categorization can continue with product and non-product
data which is non-personal.)

While the DA may attempt to differentiate data into these constituent
categories, the data itself resists the attempt to fit into these
definitions. Moreover, it is unfortunate that businesses will be
required to implement significant changes to their underlying
information technology (IT) structure without having a clear indication
that the manner in which they do so will be consistent with the DA.

In the section that follows, we discuss how difficulties with data
categorization affect African researchers.

# Barriers to International Data Transfer of Data to African Researchers 

African researchers have been highlighted in this chapter as they are
less numerous, poorly resourced, and have a greater workload as compared
to their peers in the rest of the world. For example, a Malawian
qualitative study into the challenges facing African researchers found
that lack of funds, mentorship, interest by policymakers, and a heavy
workload all contribute to the challenge for African scientists.^44^
Although some real progress has been made to develop African
researchers, this comes off a very low base. In its report on a decade
of development in Sub-Saharan African research, the World Bank noted
that international collaboration (and thus access to international data)
was a key requirement for African research.^45^ Even more telling was
the fact that collaboration with extra-regional partners outside of the
Sub-Saharan African region amounted to 42 per cent to 79 per cent of
research, far exceeding the inter-regional collaboration at 0.9 per cent
to 2.9 per cent.^46^ This, in turn, results in a tendency for African
researchers to have an asymmetric relationship with their international
partners and for them to adopt the research agenda of international
partners.^47^

In short, African researchers rely on access to the Global North for
funding, collaboration, and access to data. It is against this
background that the impact of the EU data legislation is considered.

## Lack of Clarity on Data Categorization

As illustrated earlier, the DA creates a new category of ‘product data’,
which, in turn, creates a knock-on effect on organizations who will need
to firstly define and then implement internal controls to be able to
differentiate between different types of data to create controls to
manage it. This is a thankless task as not only are there new categories
of data, but the boundaries to the categories themselves also are likely
to change as understanding of DA matures.

Even what was considered to be the settled concept of pseudonymized data
being personal data has been called into question. Additionally, as
technology and mathematical approaches are developed, previously
de-identified data may become identifiable, making pseudonymization and
anonymization techniques obsolete or ineffective.^48^

This lack of certainty means that it becomes difficult for researchers
to place the data they need in a category and so be able to determine
what rules apply to it.

# Lack of Clarity on Adequate Measures 

In its explanatory memorandum to the earlier version of the proposed DA,
the European Commission notes that 76 per cent of its respondents were
concerned about access by foreign authorities to non-personal data based
on foreign legislation, with 19 per cent indicating that it was a major
risk.^49^ This is understandable bearing in mind that there are various
countries – such as Russia – which are actively antagonistic towards the
EU. While EU data laws have the potential to facilitate access to data
by EU member states, it is quite possible – even likely – that they will
hamper non-EU states from being able to access data.

For example, Article 32(1) of the DA provides that data processing
services must take ‘all adequate technical, organisational and legal
measures, including contracts, in order to prevent international and
third-country governmental access and transfer of non-personal data held
in the Union where such transfer or access would create a conflict with
Union law or with the national law of the relevant Member State’. It is
likely that there will be a great deal of uncertainty as to what
‘adequate’ measures are that need to be taken and how these measures
differ from the requirements of international transfers in terms of the
GDPR. In the face of this uncertainty, it will simply be easier (and
more legally certain) for researchers to collaborate with their peers in
Europe. This has the potential to lump African researchers into the same
basket as Russian researchers.

At a high level, Article 32 of the DA is mostly aimed at administrative
bodies, such as a regulator or the courts and tribunals of a foreign
country, rather than researchers or their organization. But what about
local legal and political interference with regard to African
researchers?

## Political Interference with African Researchers

If an African researcher enters into an agreement with their European
counterpart to engage in a joint research project, it would be much
easier for the African administrative authority or court to order the
local researcher to divulge the product data than to attempt to
prosecute the same case in Europe. This then creates another problem,
where it is not the integrity of the researcher but rather the political
and legislative climate of the country in which the African researcher
resides that is of concern. This seems borne out by the Scholars at Risk
(SAR) network which found that of the 285 reported attacks on higher
education in 2021, 76 of these (or 26 per cent) came from African
countries.^50^ A specific example can be found in Egypt where four
members of the intellectual community – two professors, a human rights
activist, and a novelist – were also arrested for demanding that the
state take measures to guard against COVID-19 outbreaks in prison.^51^
This then raises the – unfortunately realistic – fear that it is not
only the integrity of the African researcher that is of concern but also
the likelihood of state or political interference that must be
considered before deciding to share data with an African researcher.

# Administrative Burden

Starting with the DA, the administrative burden on African researchers
to get access to data is similar to obtaining a Schengen visa for data.
While this may not seem to be a large obstacle, this can amount to a
significant barrier for African researchers and could well result in
EU–African collaboration becoming undesirable. Certainly, it is less
than clear that the claimed benefits of the DA will ‘far outweigh the
associated administrative costs’^52^ for African researchers. On the
contrary, it seems likely that the introduction of the EU data laws will
amount to something akin to a non-tariff trade barrier for African
researchers.

Similarly, the DSA refers to ‘vetted’ researchers,^53^ and it is only a
researcher who has achieved this status who has the right to access data
from the VLOPs (such as Google). Article 40(8) sets out seven
requirements for a researcher to be granted the status of a ‘vetted’
researcher, which include data security and confidentiality requirements
that African researchers may struggle to achieve. However, a more
serious obstacle facing an African researcher is the requirement that
‘the sole purpose of conducting research \[must be\] that \[it\]
contributes to the detection, identification and understanding of
systemic risks *in the Union*’.^54^ This suggests that an African
researcher requesting access to data to investigate systemic risks in an
African country would never be considered to be ‘vetted’ as the research
does not relate to the EU, which, in turn, suggests that African
researchers will only be considered when the subject matter of the
research involves the EU. This re-emphasises the point mentioned earlier
that African researchers tend to adopt the research agenda of their
international partners.

To place this in perspective, a European researcher could request access
to Meta’s data about election interference in the EU in terms of the
DSA, but an African researcher has no similar law to ask Meta for data
about election interference in Tanzania.

# Agreement Template for Data

One of the key aspects of the GDPR was the guideline on when to share
personal data and how to manage the sharing if you, as the data
controller, decide to do so. Over the years, this has become relatively
mature, and tools, such as those provided by the United Kingdom’s
Information Commissioner’s Office,^55^ have become quite sophisticated.
In contrast, there is no template for the safe transfer of product data
outside of the EU, and this uncertainty as to what should form part of
such an agreement will inevitably result in a reluctance to share
product data outside of the EU. While personal product data is already
protected by the crossborder restrictions in the GDPR,^56^ Article 32 of
the DA now introduces similar protection for non-personal product data.
Indeed, the DA itself has changed substantially from its original
proposal to now include multiple references to ‘model contractual
terms’, but whether these will include ‘model contractual terms’ to be
able to send data to an African researcher is unclear.^57^ On the
positive side, the duty of the commission to provide the ‘non-binding’
model contractual terms now has a deadline of 12 September 2025.^58^ A
similar argument can be made for data made available in terms of the
other EU Data Laws.

## Lack of Hegemony in African Legal Systems

As the initial version of the proposed DA’s explanatory memorandum
notes,^59^ regulating data at an EU member level is simply not effective
and would lead to higher transactional costs, lack of transparency,
legal uncertainty, and undesirable forum shopping.^60^ This is equally
true for approaching the regulation of data at an African Union (AU)
level, rather than country level, where the differences in legislation
are even more pronounced, despite the recent advent of the African
Continental Free Trade Area (AfCFTA).^61^ Unfortunately, the AU is
nowhere close to the type of hegemony that the EU took decades to
create. For example, the Convention on Cyber Security and Personal Data
Protection^62^ seeks to create a common vision of personal data
protection and cyber security. While this convention is, with all its
flaws,^63^ a welcome development, some nine years after it was adopted,
it only received the 15 ratifications required for it to come into
force.^64^ Instead, individual countries have adopted their own data
protection laws which have resulted in some odd variations in data
protection laws. This disharmony is illustrated by the DS-I Africa (Data
Science for Health Discovery and Innovation in Africa) group tool^65^
which compares the data protection laws of 12 English-speaking African
countries in an attempt to assist a data controller to navigate their
way through the disparate data protection laws. Some examples of the
differences are as follows: (*a*) 3 of the 12 have a definition for
pseudonymization, (*b*) personal data is sometimes referred to as
‘personal information’ and in some cases includes juristic persons,^66^
and (*c*) ‘consent’ is not a defined term in Ghana’s Data Protection Act
of 2012.^67^

While this illustrates the problem in the area of data protection, it is
worth emphasizing that none of this work has been done from a holistic
data regulation perspective as most African countries simply do not have
laws that deal with data holistically, let alone tools which facilitate
multinational comparisons in data regulation.

# Omission of Researcher Rights to Access Data 

Unlike the Digital Services Act, the Digital Markets Act simply omits
any reference to research or researchers completely, which in turn means
that researchers have to attempt to leverage third-party requests for
information in order to obtain the data they require. The failure to
acknowledge the useful work provided by researchers is a surprising
omission in the Digital Markets Act, particularly in the context of its
sister legislation.

# No Exemption for African Researcher Access to African Data

While the DA does make allowances for the user to receive his or her
data from the data holder, it does not facilitate access by African
researchers to product data generated from their country. Article 5
allows a user to request that the data holder provide their user
information to an African researcher, but obtaining multiple individual
consents to access their product data in this way may often not be
practical for African researchers. In theory, an African researcher
would be subject to Article 6 (obligations of third parties receiving
data at the request of the user), but that immediately raises the
concern of the enforceability of the DA on an African researcher who is
outside EU jurisdiction. The DA does not appear to deal with product
data emanating from a non-EU country. For example, a French
multinational company deploying smart fridges in Ghana may get
considerable product data from its Ghanian users which is repatriated to
France. Once the product data is in France, it is unclear if Ghanian
researchers would be able to get access to this product data.

# Unfair Access by EU Authorities to Data Produced Outside of the EU

While the DA does require data holders to provide information to EU
public sector bodies, it is not clear that the data must emanate from
within the EU. Consider a situation where EU health authorities are
concerned that there is an outbreak of foot-and-mouth disease in Rwanda,
but this is denied by the local Rwandan public authority. The EU health
authority may well want to requisition product data from German vaccine
producers^68^ in order to discover that the number of requests for
vaccines in Rwanda has increased substantially, supporting a move by the
EU health authorities to ban Rwandan meat products. Even more pernicious
is the fact that this product data may have no personal data component,
which could result in the EU authorities having better data on
situations in the African countries than the African country itself.

# The African Union Data Policy Framework

Up to this point, the focus has been on the digital strategy that the EU
has adopted and how it has put this into practice. As pointed out
previously, there is good reason to believe that African countries will
follow a similar path due to the Brussels effect, and this portion of
the chapter is dedicated to extrapolating what effect EU data laws will
have on African researchers.

As already noted, African countries have finally caught up with the
concept of protecting the data of individuals. However, there is a
danger that data governance is considered solely from the perspective of
the privacy of individuals, rather than from a more complex
multidimensional legal approach. Not only does data have privacy
considerations, but it also raises questions relating to other areas of
law,^69^ including competition law, consumer law, intellectual property
law, and taxation.

The DA^70^ has the potential to have a similar impact on African
countries which have a demonstrable difficulty in keeping up with the
regulation of technology. Put simply, the DA has the potential to
regulate a sector of the (data) economy which African countries have not
addressed at all. The purpose of this chapter is, at least in part, to
stimulate discussion of the regulation of data holistically in Africa in
order to avoid a situation where African countries are, once again, late
to the party and caught with their proverbial pants down. That said,
this chapter does not attempt to address every issue influencing data
regulation, but rather focuses on the impact of insufficient protection
of, and access to, data by researchers in Africa.

While African countries have not yet caught up with the developments in
data regulation, it is heartening that the recent African Union Data
Policy Framework (AUDPF), which was released in February 2022, is fully
aware of the multidimensional nature of data.^71^ The AUDPF notes that
there are no global examples of umbrella laws which regulate every
aspect of data, but rather data is regulated in data protection law,
competition law, cyber security law, electronic communications and
transactions law, and intellectual property law,^72^ and so regulatory
bodies in these areas need to coordinate their actions.^73^ While
acknowledging that African countries have less developed laws on
competition, data, and intellectual property, the AUDPF sees this as an
opportunity to harmonize legislation between African states.^74^

The AUDPF also confirms the Brussels effect and notes that African
countries are largely standard takers, rather than standard makers,^75^
and that data-rich and data-intensive developed countries tend to create
regulatory precedence.^76^ Despite this, the AUDPF does not suggest any
method to categorize data, but merely states that this should be done.
Indeed, categorization of data is so important that the AUDPF recommends
that one of the first actions by the data Information Regulator (IR) is
the categorization of data^77^ and the establishment of a common data
categorization and sharing framework.^78^ The AUDPF also recommends that
the AU should be actively lobbying the EU regarding standards and laws
relating to data.^79^ Thus, despite being aware of the importance of
data categorization as it is the foundation upon which all controlling
regulation is based, Africa still seems set to accept that the
categorization of data will be imposed on it by the EU.

The AUDPF also recognizes that there has been little restraint from
competition or data regulators on the rise of monopolistic global
platforms which are producing and extracting massive amounts of private
data which has been commodified with seemingly little regard for the
negative impacts on data subjects,^80^ effectively making competition
impossible for smaller players.^81^

In order to combat this, the AUDPF provides some recommendations on
steps that can be taken by African countries, including:

1.  The AU should be actively lobbying the EU regarding standards and
    laws relating to data.^82^

2.  Fair contractual standards for public organizations should be
    created.^83^

3.  Codes of practice for using data need to be developed.^84^

4.  Data protection rights should be considered more important than
    intellectual property rights,^85^ and contracts that give up digital
    rights, ignore personal data protection, and inhibit competition
    should be unenforceable.^86^

5.  Novel regulatory ideas could be tested in ‘regulatory
    sandboxes’.^87^

6.  Data trusts should be created to manage control of data rather than
    cede complete control to the collecting entity.^88^

7.  Universities should be included as relevant policy stakeholders to
    help establish a knowledge base from which the local data economy
    can draw scientific and technological knowledge.^89^

8.  The competition chapter of AfCFTA negotiations should set minimum
    standards to ensure that putative proprietary non-personal data is
    available to innovators, entrepreneurs, and others in the value
    chain to encourage competition across the continent.^90^

In short, what the AUDPF has done is begin the conversation about
regulating other aspects of data aside from the perspective of privacy,
but African countries are years away from implementing legislation that
deals with data holistically. Even if African countries were able to
implement legislation similar to that put into place by the EU, it is
unclear whether this would be desirable as African countries typically
have far fewer funds available for regulatory bodies, and the EU itself
is not sure what the impact of the data legislation in the EU will be;
following too quickly in EU footsteps may ironically result in African
countries taking the wrong path.

Consider, for example, the South African IR, which is the implementation
mechanism of the South African Protection of Personal Information Act
(POPIA) of 2020. In 2021–2022, the IR had a budget of approximately EUR
4.3 million^91^ while the French data protection agency, Commission
nationale de l’informatique et des libertés (National Commission on
Informatics and Liberty, CNIL), had a budget of EUR 24 million.^92^ What
is particularly startling about this disparity is that France and South
Africa have a very similar population size (approximately 63 million
people), and yet the IR is expected to do the same work as the CNIL but
with a fifth of the budget. Even a cursory look at each of the EU data
laws already dealt with makes it clear that a crucial role is played by
the regulatory bodies tasked with enforcing them. How precisely should
African countries implement similar data laws if they will never have
the funds to enforce them?

# Cutting through the Red Tape: Enabling African Researcher Access

Up to this point, this chapter has focused on the – possibly unintended
– barriers to data access for African researchers. The following section
provides some suggestions on how to reduce the barriers for African
researchers and further argues that, due to the Brussels effect which
has introduced a kind of legislative neo-colonialism, Europe has a moral
duty to expand its impact analysis of the EU data laws on the effect of
these laws outside EU borders.

# Standard Contractual Clauses for Transfers of Data

Despite there being considerable notice of the transition from Directive
95/46/ EC^93^ to the GDPR in 2018, the standard contractual clauses for
data transfers were only updated three years later.^94^ Thereafter, in
2023, the first model template for the sharing of personal data by
researchers, which combines the GDPR and the POPIA, was published in
February 2023 by the DS-I Africa Law project.^95^ While this effort is
to be commended, this template does not, understandably, even attempt to
either define or deal with the concept of ‘product data’ or ‘exportable
data’ which researchers may need to access. In order to facilitate
African researcher access, it would be helpful if this template were to
be updated to consider the requirements of different types of data, so
it is considered holistically rather than only from a privacy
perspective. It would also be helpful if the standard contractual
clauses for the transfer of product data would be made available by the
EU in a much shorter time frame, in order to provide some assistance to
African researchers wishing to access data.

# Code of Conduct for Researchers

One way to ease the burden on African researchers would be for the EU to
provide a guideline that researchers, governed by an approved code of
conduct, would be able to receive data; or, put differently, researchers
governed by that code of conduct would be considered to pass the test of
Article 32(1) of the DA that says ‘all adequate technical,
organisational and legal measures, including contracts, in order to
prevent international and third-country governmental access and transfer
of non-personal data held in the Union where such transfer or access
would create a conflict with Union law or with the national law of the
relevant Member State’*. *

At present there are not many codes of conduct, and those that do exist
are intended to address data protection, rather than data holistically.
One such example is the draft Code of Conduct for Research promulgated
in terms of the POPIA.^96^ While this code does introduce concepts that
are not present in its enabling legislation (such as
pseudonymization),^97^ it is clearly focused on personal data^98^ and
does not consider other data and how this would be managed for the
purposes of research. As with the standard contractual clauses mentioned
earlier, this may well be the time to start considering a holistic code
of conduct that deals with all data types.

# AU Conventions Dealing with Data 

The AUDPF is a very useful and necessary step in the development of
African policy on data, but it does come several years after the same
step was taken by the European strategy for data. In a manner similar to
the Malabo Convention, it may be useful for the AU to propose a
convention which would incorporate the concepts put forth in the
DSA,^99^ the DMA,^100^ the AIA,^101^ and the DA.^102^ That said, the
pace of the ratification of the Malabo Convention would suggest that it
would take decades before conventions of this nature would be adopted
and ratified.

Interestingly, the AUDPF suggests that the use of a ‘regulatory sandbox’
could be appropriate for situations such as these.^103^ Regulatory
sandboxes are a regulatory approach, typically summarized in writing and
published, that allow live, timebound testing of innovations under a
regulator’s oversight. Novel financial products, technologies, and
business models can be tested under a set of rules, supervision
requirements, and appropriate safeguards. This has the benefit of
encouraging experimentation, reducing barriers to entry, and allowing
regulators to get valuable insight into how to regulate the sector. In
2018, approximately 20 countries were actively exploring the concept of
regulatory sandboxes.^104^

**Evaluation of Impact of Data Laws on African **

# Countries

Bearing in mind the novelty of the data laws, the EU wisely commissioned
impact assessments and conducted participant studies and questionnaires
over several years – for example, on the impact of the DA – but all of
these were from an EU member country’s perspective.^105^ Unsurprisingly,
this impact assessment did not meaningfully address the possible impact
that the EU data laws could have on Africa and on African
researchers.^106^ This does not mean that EU data laws will not have an
impact on Africa – just that there is no plan to measure it.

The EU also created a mechanism of ex-post evaluations in order to
assess whether the objectives of EU data laws were, in fact, being
realized. Once again, this is an entirely logical approach to developing
novel regulations and appears to be standard practice for the EU. In
contrast, while it is undoubtably a wise plan to commission both impact
assessments and ex-post evaluations of legislation, in practice this
tends not to be done for African countries, even for legislation that
they themselves are implementing. As a result, there is a vanishingly
small chance that the impact of EU data laws has been assessed by any
African country, and it is also unlikely that any plans exist to
evaluate the impact of EU data laws once they come into force. Instead,
African countries and researchers are likely to start experiencing
difficulties in an anecdotal way, similar to what they probably
experienced when first encountering personal data protection laws.

While it may be too late to commission an impact assessment, an ex-post
evaluation on the impact of EU data laws on African countries,
companies, and individuals would be most useful to understand the local
conditions and implications of regulating data and also the results of
failing to do so. This has the potential added benefit of increasing
regulatory harmony between African countries and the EU, which, in turn,
would facilitate data transfer. Indeed, the implications of failing to
consider and implement similar laws within African countries could well
lead to a missed opportunity, particularly when, for example, the EU
estimates that unused product data has the potential to unlock EUR 1.5
trillion (USD 15.842 trillion)^107^ of value by 2027.^108^ To put this
in some perspective, the country with the highest gross domestic product
(GDP) in Africa is Nigeria at USD 441 billion,^109^ and the combined GDP
of all African countries in 2021 amounted to USD 2.7 trillion. This
means that the value of unused product data in Europe is equal to
approximately half the GDP of the African continent.

# Conclusion

By pioneering the need to unlock the value of data, the EU has a
first-mover advantage over African countries. African countries, on the
other hand, are desperately trying to keep pace with the speed of
changes in the regulation of data. The EU should have, at least, some
empathy for Africa because it was the EU that suffered from not being
the first mover when it came to technical innovations, which may account
for so many US tech companies and so few EU tech companies in the top 20
global tech companies.^110^

The introduction of EU data laws seems to have the potential to have the
(unintended) consequence of further alienating African researchers and
creating new barriers to cooperation with their EU counterparts.
Moreover, their EU counterparts will have greater (if not perfect)^111^
access to data. This means that EU researchers are likely to feel the
benefits of EU data laws while the African researchers are likely to
suffer the detrimental effects. This is ironic, particularly in light of
the moral imperative for the EU to deal fairly with countries that it
colonized and bearing in mind the amount of aid the EU provides to
Africa.

If the EU, as a highly literate and technically advanced society, can be
said to be only unlocking a fraction of the value of the data available
to it, then that statement is surely even more applicable to African
countries. There must be tremendous potential for researchers to make
meaningful differences in Africa, provided they can get access to data
which could be unlocked by EU data laws. For example, it could be hugely
beneficial if the EU would support African countries being able to
access their own product data from global tech companies, such as Google
and Amazon.

African countries should be closely watching the success (or failure) of
EU data laws as facilitating access to data has the potential of
bringing about an even more dramatic change in Africa than it would in
the EU. This is more apposite when considering the relative lack of
sophistication in existing African laws. To amend a well-known adage,
give a researcher the answer and you solve the problem of the day, but
give her access to data and you help her solve problems for a lifetime.

# Notes

1.  Eurostat Statistics Explained, ‘Archive: Africa–EU – International
    Trade in Goods Statistics’, February 2022,
    https://ec.europa.eu/eurostat/statisticsexplained/index.php?title=Archive:Africa-EU\_-\_international\_trade\_in\_
    goods\_statistics (accessed 25 February 2023).

2.  European Commission, ‘EU Trade Relations with South Africa: Facts,
    Figures and Latest Developments’, EU Directorate-General for Trade,
    https://policy.trade.ec.europa.eu/eu-trade-relationships-country-andregion/countries-and-regions/south-africa\_en\#:\~:text=The%20EU%20
    represents%20the%20most,country’s%20industrialisation%20and%20
    transformation%20agenda (accessed 25 February 2023).

3.  Anu Bradford, *The Brussels Effect: How the European Union Rules the
    World* (Oxford University Press, 2020).

4.  ‘Data Protection and Privacy Legislation Worldwide’, UN Trade and
    Development, 14 December 2021,
    https://unctad.org/page/data-protectionand-privacy-legislation-worldwide
    (accessed on 25 February 2023).

5.  Michael Pisa, Pam Dixon, and Ugonma Nwankwo, ‘Why Data UNCTAD
    Protection Matters for Development: The Case for Strengthening
    Inclusion and Regulatory Capacity’, Centre for Global Development,
    December 2021,
    https://www.cgdev.org/sites/default/files/why-data-protection-matters-fordevelopment.pdf
    (accessed 25 February 2023).

6.  Bradford, *The Brussels Effect*, 80.

7.  Bradford, *The Brussels Effect*, 80.

8.  Bradford, *The Brussels Effect*, 94.

9.  See, for example, Commission Decision in Case No. COMP/B-2/38.381
    (De Beers), C(2006) 521 final (22 February 2006), cited in 2006 O.J.
    (L 205) 24.

10. Bradford, *The Brussels Effect*, 80.

11. ‘A European Strategy for Data’, European Commission, 19 February
    2020, https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A
    52020DC0066 (accessed 7 June 2023).

12. Regulation (EU) 2018/1807.

13. Bradford, *The Brussels Effect*, 4–5.

14. ‘A European Strategy for Data’, 7.

15. ‘A European Strategy for Data’, 22.

16. ‘Regulation (EU) 2022/2065 of the European Parliament and of the
    Council of 19 October 2022 on a Single Market for Digital Services
    and Amending Directive 2000/31/EC (Digital Services Act)’,
    https://eur-lex.europa.eu/
    legal-content/en/TXT/?uri=CELEX%3A32022R2065 (accessed 8 June 2023).

17. ‘Regulation (EU) 2022/1925 of the European Parliament and of the
    Council of 14 September 2022 on Contestable and Fair Markets in the
    Digital Sector and Amending Directives (EU) 2019/1937 and (EU)
    2020/1828 (Digital Markets Act)’,
    https://eur-lex.europa.eu/legal-content/EN/
    TXT/?uri=CELEX%3A32022R1925 (accessed 8 June 2023).

18. ‘European Parliament Legislative Resolution of 13 March 2024 on the
    Proposal for a Regulation of the European Parliament and of the
    Council to Lay Down Harmonised Rules on Artificial Intelligence
    (Artificial Intelligence Act) and to Amend Certain Union Legislative
    Acts (COM(2021)0206 –

> C9-0146/2021 – 2021/0106 (COD)) Regulation (EU) 2021/206 of the
> European Parliament and of the Council Laying Down Harmonized Rules on
> Artificial Intelligence (Artificial Intelligence Act) and Amending
> Certain Union Legislative Acts’,
> https://www.europarl.europa.eu/doceo/document/ TA-9-2024-0138\_EN.pdf
> (accessed 8 April 2024).

1.  ‘Regulation (EU) 2023/2854 of the European Parliament and of the
    Council of 13 December 2023 on Harmonized Rules for Fair Access to
    and Use of Data and Amending Regulation (EU) 2017/2394 and Directive
    (EU) 2020/1828 (Data Act)’,
    https://eur-lex.europa.eu/legal-content/EN/
    TXT/?uri=celex%3A32023R2854 (accessed 28 March 2024).

2.  A list of the very large online platforms (VLOPs) and very large
    online search engines (VLOSEs) was published on 23 April 2023.
    European Commission, *Digital Services Act: Commission Designates
    First Set of Very Large Online Platforms and Search Engines*,
    https://ec.europa.eu/commission/presscorner/ detail/en/IP\_23\_2413
    (accessed 24 October 2023).

3.  On 6 September 2023, the European Commission determined that six
    companies – Alphabet, Amazon, Apple, ByteDance, Meta, and Microsoft
    – were gatekeepers in terms of the DMA. ‘Digital Markets Act:
    Commission Designates Six Gatekeepers’, European Commission, 6
    September 2023, https://perma.cc/KR8U-JQ8D (accessed 22 October
    2023).

4.  ‘European Parliament Legislative Resolution of 13 March 2024 on the
    Proposal for a Regulation of the European Parliament and of the
    Council on Laying Down Harmonized Rules on Artificial Intelligence
    (Artificial Intelligence Act) and Amending Certain Union Legislative
    Acts (COM (2021) 0206 – C9-0146/2021 – 2021/0106 (COD))’,
    https://www.europarl.europa.eu/
    doceo/document/TA-9-2024-0138-FNL-COR01\_EN.pdf (accessed 8 April
    2024).

5.  AIA, Article 6.

6.  AIA, Article 9.

7.  AIA, Articles 10-12.

8.  AIA, Article 14(4)(e).

9.  AIA, Article 28.

10. AIA, Article 70.

11. AIA, Article 74. The national authority carrying out the activities
    and taking the measures pursuant to Regulation (EU) 2019/1020.

12. AIA, Article 13(3)(b)(v).

13. ‘Regulation (EU) 2023/2854 of the European Parliament and of the
    Council of 13 December 2023’.

14. ‘Proposal for a Regulation of the European Parliament and of the
    Council on Harmonised Rules on Fair Access to and Use of Data (Data
    Act) COM/2022/68’, https://eur-lex.europa.eu/legal-content/EN/TXT/?
    uri=COM%3A2022%3A68%3AFIN (accessed 8 June 2023); Regulation (EU)
    2023/2854 of the European Parliament and of the Council of 13
    December 2023’. Although this refers to the proposal of the DA
    rather than its final version, this vision of the DA remains
    apposite.

15. Case T-557/20 *Single Resolution Board v. European Data Protection
    Supervisor* \[2023\] ECLI:EU:2023”219,
    https://eur-lex.europa.eu/legal-content/EN/
    TXT/?uri=CELEX%3A62020TJ0557 (accessed 15 December 2024).

16. See, for example, the statement by Thomas Zerdick, head of
    technology and privacy at the EDPS: ‘Unlike anonymised data,
    pseudonymised data qualifies as personal data under the General Data
    Protection Regulation (GDPR)’. Thomas Zerdick, ‘Pseudonoymous Data:
    Processing Personal Data while Mitigating Risks’, European Data
    Protection Supervisor, 21 December 2021,
    https://edps.europa.eu/press-publications/press-news/blog/pseudonymousdata-processing-personal-data-while-mitigating\_en
    (accessed 28 July 2023). For a South African perspective on whether
    pseudonymized data is always personal data, see D. W. Thaldar, ‘Does
    Data Protection Law in South Africa Apply to Pseudonymised Data?’
    *Frontiers in Pharmacology*, 23 November 2023, DOI:
    https://doi.org/10.3389/fphar.2023.1238749.

17. ‘Regulation (EU) 2018/1725 of the European Parliament and of the
    Council of 23 October 2018 on the Protection of Natural Persons with
    Regard to the Processing of Personal Data by the Union Institutions,
    Bodies, Offices and

> Agencies and on the Free Movement of Such Data, and Repealing
> Regulation (EC) No 45/2001 and Decision No 1247/2002/EC’, \[2018\] OJ
> L 295, https://eur-lex.europa.eu/eli/reg/2018/1725/oj (accessed 15
> December 2024).

1.  ‘Regulation (EU) 2018/1725 of the European Parliament and of the
    Council of 23 October 2018’.

2.  ‘Appeal Brought on 5 July 2023 by the European Data Protection
    Supervisor against the Judgment of the General Court (Eighth
    Chamber, Extended Composition) Delivered on 26 April 2023 in Case
    T-557/20, *Single Resolution Board v European Data Protection
    Supervisor* (Case C-413/23 P)’,
    https://eurlex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:62023CN0413
    (accessed 15 December 2024).

3.  DA, Article 2(5,15).

4.  DA, Article 2(5).

5.  Bertin Martens, ‘How to Fix the European Union’s Proposed Data Act’,
    Bruegel, 4 December 2022,
    https://www.bruegel.org/blog-post/how-fixeuropean-unions-proposed-data-act
    (accessed 28 February 2023).

6.  DA, Article 2(38).

7.  DA, Article 2(16–17).

8.  Note that this is owned by the data subject.

9.  Save Kumwenda, El Hadji A. Niang, Pauline W. Orondo, Pote William,
    Lateefah Oyinlola, Gedeon N. Bongo, and Bernadette Chiwona,
    ‘Challenges Facing Young African Scientists in Their Research
    Careers: A Qualitative Exploratory Study’, *Malawi Medical Journal*
    29, no. 1 (2017): 1–4.

10. World Bank Group and Elsevier, *A Decade of Development in
    Sub-Saharan African Science, Technology, Engineering and Mathematics
    Research* (2014), 48,
    https://documents1.worldbank.org/curated/en/237371468204551128/
    pdf/910160WP0P126900disclose09026020140.pdf (accessed 15 December
    2024.).

11. World Bank Group and Elsevier, *A Decade of Development*, 34.

12. J. Cerdeira, J. Mesquita, and, E. S. Vieira, ‘International Research
    Collaboration: Is Africa Different? A Cross-Country Panel Data
    Analysis’, *Scientometrics* 128 (2023): 2145–2174.

13. Emily M. Weitzenboeck, Pierre Lison, Malgorzata Cyndecka, and
    Malcolm Langford, ‘The GDPR and Unstructured Data: Is Anonymization
    Possible?’ *International Data Privacy Law* 12, no. 3 (2022):
    184–206.

14. ‘Proposal for a Regulation of the European Parliament and of the
    Council’.

15. ‘Attacks on Scholars a Threat to Democracy in Africa: The Link
    between Decreased Academic Freedom and the Stagnation of Democracy’,
    Reliefweb, 25 May 2022,
    https://reliefweb.int/report/world/attacks-scholars-threatdemocracy-africa-link-between-decreased-academic-freedom-andstagnation-democracy
    (accessed 23 October 2023).

16. ‘Attacks on Scholars a Threat to Democracy in Africa’.

17. ‘Proposal for a Regulation of the European Parliament and of the
    Council’.

18. ‘Regulation (EU) 2022/2065 of the European Parliament and of the
    Council of 19 October 2022 on a Single Market for Digital Services
    and Amending Directive 2000/31/EC (Digital Services Act)’,
    https://eur-lex.europa.eu/
    legal-content/en/TXT/?uri=CELEX%3A32022R2065 (accessed 8 June 2023),
    Recitals 92, 124, and 137, and Articles 39(3) and 40(8).

19. ‘‘Regulation (EU) 2022/2065 of the European Parliament and of the
    Council of 19 October 2022’, Article 40(4) as read with Article
    40(8)(e) (emphasis added).

20. Elizabeth Denham, ‘Data Sharing: A Code of Practice’, Information
    Commissioner’s Office, May 2021,
    https://ico.org.uk/for-organisations/ukgdpr-guidance-and-resources/data-sharing/data-sharing-a-code-of-practice
    (accessed 15 December 2024).

21. European Union, ‘Regulation (EU) 2016/679 of the European Parliament
    and of the Council of 27 April 2016 on the Protection of Natural
    Persons with Regard to the Processing of Personal Data and on the
    Free Movement of Such Data, and Repealing Directive 95/46/EC
    (General Data Protection Regulation)’ \[2016\] OJ L119/1, Articles
    44–50.

22. DA, Article 41.

23. DA, Article 41.

24. ‘Proposal for a Regulation of the European Parliament and of the
    Council’; DA, 7–8.

25. ‘Proposal for a Regulation of the European Parliament and of the
    Council’.

26. ‘Creating One African Market’, AfTACF Symposium, August 2023,
    https:// au-afcfta.org (accessed 15 December 2024).

27. ‘African Union Convention on Cyber Security and Data Protection’,
    https://
    au.int/sites/default/files/treaties/29560-treaty-0048\_-\_african\_union\_
    convention\_on\_cyber\_security\_and\_personal\_data\_protection\_e.pdf
    (accessed 15 December 2024).

28. Paul Esselaar, Alison Gillwald, Ashly Hope, Gavin van der Nest, and
    John Stuart, ‘Aligning Data Protection Laws in Africa to Facilitate
    E-Commerce’, Tralac, 1 June 2020,
    https://www.tralac.org/publications/article/14641trade-in-the-digital-economy-a-tralac-collection.html
    (accessed 15 December 2024).

29. Also known as the Malombo Convention. Only 13 countries have
    ratified the convention as of 28 February 2023. See
    https://au.int/sites/default/
    files/treaties/29560-treaty-0048\_-\_african\_union\_convention\_on\_cyber\_
    security\_and\_personal\_data\_protection\_e.pdf (accessed 15
    December 2024).

30. ‘Search and Compare Data Protection Legislation’, DS-I Africa,
    https:// www.datalaw.africa/law/search\_compare (accessed 15
    December 2024).

31. South Africa’s Protection of Personal Information Act (Act no. 4 of
    2013).

32. Ghana, Data Protection Act, 2012 (Act 843), published in the Ghana
    Gazette No. 39, 16 October 2012.

33. In terms of DA, Articles 14 and 15.

34. D. W. Thaldar, B. A. Townsend, D-L. Donnelly, M. Botes, A.
    Gooden, J. Van Harmelen, and B. Shozi, ‘The Multidimensional Legal
    Nature of Personal Genomic Sequence Data: A South African
    Perspective’, *Frontiers in Genetics* 13 (2022), DOI:
    https://doi.org/10.3389/fgene.2022.997595.

35. ‘Regulation (EU) 2023/2854 of the European Parliament and of the
    Council of 13 December 2023’.

36. ‘AU Data Policy Framework’, African Union, February 2022, https://
    au.int/sites/default/files/documents/42078-doc-AU-DATA-POLICYFRAMEWORK-ENG1.pdf
    (accessed 29 July 2023).

37. ‘AU Data Policy Framework’, 11.

38. ‘AU Data Policy Framework’, 31.

39. ‘AU Data Policy Framework’, 12.

40. ‘AU Data Policy Framework’, 1, 17.

41. ‘AU Data Policy Framework’, 1.

42. ‘AU Data Policy Framework’, vii.

43. ‘AU Data Policy Framework’, x, 20, 59.

44. ‘AU Data Policy Framework’, 12.

45. ‘AU Data Policy Framework’, 8.

46. ‘AU Data Policy Framework’, 24.

47. ‘AU Data Policy Framework’, 12.

48. ‘AU Data Policy Framework’, 25.

49. ‘AU Data Policy Framework’, 28.

50. ‘AU Data Policy Framework’, 34.

51. ‘AU Data Policy Framework’, 35. In *Discovery Limited and Others v.
    Liberty Group Limited*, a solution to the multitude of interests in
    data was defined, upholding both data protection and competition. In
    essence, the court held that in such disputes, if the data is
    personal in nature, it is ‘owned’ by the data subject, and
    competitors may not exclude others from accessing this information.
    ZAGPJHC 67, \[2000\], https://www.saflii.org/za/cases/
    ZAGPJHC/2020/67.html (accessed 30 July 2023).

52. ‘AU Data Policy Framework’, 39.

53. ‘AU Data Policy Framework’, 47.

54. ‘AU Data Policy Framework’, 56.

55. ‘AU Data Policy Framework’, 57.

56. *Annual Report of the Information Regulator 2021/22*, https://www.
    inforegulator.org.za/wp-content/uploads/2022/10/Info%20Regulator%20
    Annual%20Report%202021-22-compressed.pdf (accessed 24 October 2023).

57. ‘Overview on Resources Made Available by Member States to the Data
    Protection Supervisory Authorities’, European Data Protection Board,
    5 September 2022 https://edpb.europa.eu/system/files/2022-09/edpb\_
    overviewresourcesmade\_availablebymemberstatestosas2022\_en.pdf
    (accessed 24 October 2023).

58. This is the predecessor of the EU GDPR. Directive 95/46/EC of the
    European Parliament and of the Council of 24 October 1995 on the
    Protection of Individuals with Regard to the Processing of Personal
    Data and on the Free Movement of Such Data (the Data Protection
    Directive).

59. ‘Standard Contractual Clauses (SCC) Standard Contractual Clauses for
    Data Transfers between EU and Non-EU Countries’, European
    Commission, 4 June 2021,
    https://commission.europa.eu/law/law-topic/data-protection/
    international-dimension-data-protection/standard-contractual-clauses-scc\_
    en (accessed 15 December 2024).

60. Lee Swales, Paul Ogendi, Marietjie Botes, Beverley Townsend,
    Dusty-Lee Donnelly, Lukman Abdulrauf, and Donrich Thaldar, ‘A Data
    Transfer Agreement (DTA) Template for South Africa’, Zenodo, 6
    February, 2023, https://zenodo.org/record/7537396\#.Y\_iYDexBxB
    (accessed 15 December 2024). See also L. Swales, M. Botes, D-L.
    Donnelly, and D. W. Thaldar, ‘Towards a Data Transfer Agreement for
    the South African Research Community: The Empowerment Approach’,
    *South African Journal of Bioethics and Law* 16, no. 1 (2023):
    13–18.

61. ‘Government Gazette Vol. 695’, Republic of South Africa, 12 May
    2023,
    https://inforegulator.org.za/wp-content/uploads/2020/07/GovernmentGazzette-dated-12-May-.pdf
    (accessed 15 December 2024). For a discussion of the draft Code of
    Conduct for Research, see D. W. Thaldar and B. Townsend, ‘Protecting
    Personal Information in Research: Is a Code of Conduct the
    Solution?’ *South African Journal of Science* 117, nos. 3–4 (2021),
    DOI: https://doi.org/10.17159/sajs.2021/9490; A. Gooden and D. W.
    Thaldar, ‘Despite Good Progress with Regard to the Proposed Code of
    Conduct for Research in South Africa, Unresolved Issues Remain’,
    *Humanities and Social Sciences Communications* (2024), DOI:
    https://doi. org/10.1057/s41599-024-02715-0.

62. See, for example, clause 4.2.2.3 of the Code of Conduct, which
    states that researchers must ‘ensure that the Personal Information
    is Pseudonymised unless there is a compelling reason why it is not
    feasible or appropriate’.

63. Referred to as ‘personal information’.

64. ‘Regulation (EU) 2022/2065 of the European Parliament and of the
    Council of 19 October 2022 on a Single Market for Digital Services
    and Amending Directive 2000/31/EC (Digital Services Act)’,
    https://eur-lex.europa.eu/
    legal-content/en/TXT/?uri=CELEX%3A32022R2065 (accessed 8 June 2023).

65. ‘Regulation (EU) 2022/1925 of the European Parliament and of the
    Council of 14 September 2022 on Contestable and Fair Markets in the
    Digital Sector and Amending Directives (EU) 2019/1937 and (EU)
    2020/1828 (Digital Markets Act)’,
    https://eur-lex.europa.eu/legal-content/EN/
    TXT/?uri=CELEX%3A32022R1925 (accessed 8 June 2023).

66. European Parliament legislative resolution of 13 March 2024 on the
    proposal for a regulation of the European Parliament and of the
    Council to lay down harmonized rules on Artificial Intelligence
    (Artificial Intelligence Act) and to amend certain Union Legislative
    Acts (COM(2021)0206 – C9-0146/2021 – 2021/0106(COD)),
    https://www.europarl.europa.eu/doceo/document/TA9-2024-0138\_EN.pdf
    (accessed 8 April 2024).

67. Ibid.; ‘Regulation (EU) 2023/2854 of the European Parliament and of
    the Council of 13 December 2023’.

68. ‘AU Data Policy Framework’, 39.

69. ‘Briefing on Regulatory Sandboxes’, United Nations
    Secretary-General’s Special Advocate for Inclusive Finance for
    Development (UNSGSA),
    https://www.unsgsa.org/sites/default/files/resources-files/2020-09/Fintech\_
    Briefing\_Paper\_Regulatory\_Sandboxes.pdf (accessed 15 December
    2024).

70. ‘Impact Assessment Report and Support Studies Accompanying the
    Proposal for a Data Act’,
    https://digital-strategy.ec.europa.eu/en/library/impactassessment-report-and-support-studies-accompanying-proposal-data-act
    (accessed 8 April 2024).

71. ‘Public Consultation on the Data Act: Summary Report’,
    https://ec.europa.

> eu/newsroom/dae/redirection/document/81599 (accessed 15 December
> 2024).

1.  This is as of as of 25 February 2023.
    https://www.xe.com/currencyconverter/

> convert/?Amount=15000000000000&From=EUR&To=USD (accessed 25 February
> 2023).

1.  ‘A European Strategy for Data’, Communication from the Commission to
    the European Parliament, the Council, the European Economic and
    Social Committee and the Committee of the Regions, 19 February 2020,
    https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1593073685620&
    uri=CELEX%3A52020DC0066 (accessed 25 February 2023).

2.  ‘African Countries with the Highest Gross Domestic Product (GDP) in
    2021’, Statista, 2021,
    https://www.statista.com/statistics/1120999/gdp-ofafrican-countries-by-country
    (accessed 25 February 2023).

3.  ‘Market capitalization of Apple (AAPL)’, Apple, 2023, https://
    companiesmarketcap.com/tech/largest-tech-companies-by-market-cap
    (accessed 25 February 2023).

4.  It is unclear why the right to access product data is limited to the
    user and the person nominated by the user in the DA. The first
    reference to ‘research’ is located in Article 21 which focuses on
    access by researchers to public bodies, rather than ‘data holders’.
    Interestingly, the final version of the DA introduced Article 44(3)
    which indicates that the DA is without prejudice to union and
    national law, providing for ‘access to and authorizing the use of
    data for scientific research purposes’ which may turn out to be a
    backdoor into access by African researchers to data held in the EU.

[^09chapter6_1]: This work was supported by the United States’s National Institute
    of Mental Health and the National Institutes of Health (award number
    U01MH127690) under the Harnessing Data Science for Health Discovery
    and Innovation in Africa (DS-I Africa) programme. The content of
    this chapter is solely the author’s responsibility and does not
    necessarily represent the official views of the aforementioned
    institutes.
