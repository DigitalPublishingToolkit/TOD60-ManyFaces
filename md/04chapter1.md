---
Pr-id: MoneyLab
P-id: INC Reader
A-id: 10
Type: article
Book-type: anthology
Anthology item: article
Item-id: unique no.
Article-title: title of the article
Article-status: accepted
Author: name(s) of author(s)
Author-email:   corresponding address
Author-bio:  about the author
Abstract:   short description of the article (100 words)
Keywords:   50 keywords for search and indexing
Rights: CC BY-NC 4.0
...


# Data Access for research: 

# Imaginations, limitations and promises

# Jef Ausloos and Siddharth Peter de Souza

Throughout the last decade, concerns have been growing over the (lack
of) transparency of digital infrastructures. While these infrastructures
have rapidly nested themselves into every part of society – from social
and professional contexts to industrial and bureaucratic processes –
their inner workings have remained shrouded in secrecy to outside
viewers. This fundamentally challenges the ability to observe, and
understand, the world around us, whether it be for public scrutiny and
accountability purposes or for different kinds of knowledge production
more broadly. Indeed, independent researchers – from academia,
investigative journalism, and civil society – have decried the many
legal, technical, financial, and other obstacles preventing them from
observing and scrutinizing the data, algorithms, and general operation
of these digital infrastructures.

Over the years, a wide variety of measures have been proposed and tested
to overcome the obstacles faced. These range from methodological tools
developed by the research community (for example, web scraping) to
self-regulatory initiatives (for example, data philanthropy) and policy
proposals (for example, Article 40 in the European Union’s \[EU\]
Digital Services Act).^1^ Regulators across the world have recently
stepped up, proposing legal frameworks targeting a range of issues
raised by digital infrastructures. The EU regulator in particular has
put forward a barrage of legislation purported to boost transparency and
facilitate data access.^2^ These proposals are primarily conceived in
light of internal market goals, often disregarding alternative purposes
and interests: from holding different sources of power to account to
diverse forms of knowledge production in a digitally intermediated
world. Data access for independent research – the central theme in this
volume – only features in the margins of these new frameworks, if at
all.

The explosion of new and proposed legal frameworks can also lead to
regulatory inflation, which is the increase in regulatory requirements,
overwhelming under-resourced and under-represented interest groups in
trying to make sense of transparency and access provisions. More often
than not, overambitious legislative action may effectively result in a
denial-of-service attack, hijacking the limited resources, capacity, and
imaginaries of change of those they purport to empower. As such, while
ostensibly aiming to reign in the power of digital infrastructures,
these new legal frameworks when combined may further solidify the power
of those with the resources to manage the operationalization of the law.

This tumultuous landscape of multifarious legislative action along with
the political economy of digital infrastructures more broadly also calls
for a reappraisal of the need and conditions for independent research in
the first place. Transparency and data access for independent
researchers may seem laudable goals in the abstract, but to what end?
What and whom do these debates obscure? What are, or should be, the
goals and interests of (academic) researchers demanding access to
digital infrastructures? In short, there is a clear need for critical
and global reflection on how new data access rules shape research
agendas but also on the positionality of different actors in these
debates.

This is why, in March 2023, we organized a small-scale workshop at the
Institute for Information Law, University of Amsterdam. The explicit
goal was to bring together a group of academics from different
backgrounds and provide a platform for critically exploring key issues
relating to the regulation of access to data for research. Around 30
participants were selected based on a call for participation, with
particular attention to geographical, disciplinary, and career-level
diversity. To facilitate this, we were lucky enough to secure
institutional funding for covering travel expenses of participants from
five different continents.

Participants were invited to submit draft papers presenting their ideas
and provocations on a range of themes and questions. These were
circulated beforehand and discussed in depth during the workshop. During
these discussions, we debated issues such as the opportunities and
challenges of the law as a tool for observing digital infrastructures;
how data access regimes may privilege certain geographical and
institutional contexts; and how it may affect different kinds of
dependencies. We also discussed work that critically looks at academia’s
data production, use, and ownership, as well as the political economy of
data access for research and the multifarious power dynamics between
academia, private/ public sector, and civil society.

Based on these conversations and further written feedback on their work,
authors developed their papers into the chapters presented in this
volume. We rejoice in the fact that these chapters reflect the
exploratory ambitions we had for the workshop, welcoming many different
perspectives beyond dominant legalese or Eurocentric narratives. It is
precisely by combining these different scopes and angles that we hope to
challenge readers in their thinking and expand their imaginations on the
topic of (researcher) data access to digital infrastructures. The
chapters in this volume cover legal, technical, political, didactic, and
social questions, at different jurisdictional levels and deploying
different methodologies, from doctrinal and historical work to
empirical, auto ethnographic, and participatory action research.

As academics are increasingly demanding for data access to digital
infrastructures, and a growing number of data access regimes are seeing
the light of day, it is important to keep asking big and critical
questions: What is the agenda-setting power afforded by data access
regimes? Whom are these regimes for, or whom should they be for in light
of the politics of knowledge production? How do they nurture and/or
challenge existing structures of power in academia, politics, and
industry? While this volume certainly does not purport to answer these
vital questions, we hope that it does reveal the richness of the debate,
prompt new questions, and inspire to challenge existing paradigms.

Before getting to the different contributions, we want to use this
introductory chapter to explore – what we consider – a few pivotal
concepts in the debate on researcher data access to digital
infrastructures. Specifically, we look at the notion of ‘data access’
and its different epistemologies. Building on this, we also consolidate
different critical perspectives on researcher data access into the
notion of the ‘academic data gaze’. This, finally, will also allow us to
uncover some of the underlying power dynamics at play in these issues
and debates.

All in all, we want this chapter to invite the academic community to
self-reflect on critical questions brought to the surface in the
researcher data access debate. Pluralizing what we understand data to
be, data to do, and data access to include; the role of academia as
agents to challenge data-driven power; as well as academia’s own
complicity in allowing structures of power. Put differently, we cannot
be content with taking data access provisions and academic claims to
data at face value but need to consider their underlying logics and
politics.^3^ This is particularly necessary because academic data access
is a function of different understandings of data, and also because the
avenues to access are unequal depending on resources, technical
capacity, as well as institutional protections. As academics therefore,
it is important to have ‘awareness of one’s own epistemological
commitments’, as well as reflect and acknowledge that one’s epistemic
choices have effects on others.^4^ This volume is therefore an
opportunity to unpack tensions that emerge in securing data access for
researchers, while also being conscious that the contexts within which
this work is produced, and our conferences are organized, remain places
of immense privilege.

## The Epistemic Questions behind Data Access 

The intersections between data, access, and knowledge production become
important starting points to be able to unpack data access for research.
To begin with, in thinking about data, we wish to ascertain the various
characteristics, imaginaries, and values that influence how data is
understood and regulated.^5^ If one is to look at the business models of
companies and their digital infrastructures, the regulations emerging
from transnational organizations such as the World Trade Organization or
at a regional level the EU regulation on data governance, it becomes
clear that data is conceived to be an economic commodity – one that can
be brokered, traded, and used as a resource to extract value.^6^ The
notion of ‘data as the new oil’ has resulted in regulation across the
world taking an approach which examines how best to regulate the ‘data
market’.^7^ This approach aims to ensure that regulation of data does
not restrict innovation and fosters competition and growth of the tech
industry. Such an approach, while being by far the more prevalent, is
not the only notion of data that is relevant to pay attention to.

For instance, if one is to look at the work of indigenous data
sovereignty experts, then a key characteristic of data is that it is
living.^8^ This entails that data plays an important role in determining
the personhood as well as the embodied experiences that people have.
Data is something that is central to a person’s autonomy and sense of
respect.^9^ This emphasis on people’s agency confronts motivations of
open data, where there is an emphasis on data sharing without adequate
reflection on the power structures and historical conditions that
underpin how data sharing and exchange has been constructed.^10^

That data is not a resource that can be commodified is powerfully
explained through the work of We Are Not Numbers, a Gazan youth group.
The world often speaks about Palestinians in terms of numbers –
‘specifically, how many killed, injured, homeless and/or dependent on
aid. But numbers are impersonal and often numbing. What they don’t
convey are the daily personal struggles and triumphs, the tears and the
laughter, and the aspirations that are so universal that if it weren’t
for the context, they would immediately resonate with virtually
everyone.’^11^ This distinction is important because it situates how
treating data as a resource detaches personhood and dehumanizes what is
represented in that data into an objective, commensurable fact, devoid
of nuance and context.^12^

Another understanding of data is that it is not something that just
exists in nature,^13^ but it is a consequence of labour that is put in
by people, oftentimes in exploitative scenarios. We have seen recently
how corporations around the world are exploiting economic conditions to
find the cheapest labour to perform ‘data work’ such as in relation to
labelling, curating, and sorting of data.^14^ Such workers are paid
measly amounts of money and often do not have safe working conditions
when they deal with data about violent circumstances, as has been seen
in a recent case of OpenAI in Kenya.^15^ Amazon Mechanical Turk is an
example of a crowdsourcing platform where companies are accessing
digital labour at low costs without any obligations towards worker
security and social protection.^16^

Data also does not just affect the individual person but also
systematizes relations between people and/or objects and digital
infrastructures.^17^ As Salome Viljoen has argued, ‘\[B\]y engaging with
datafied systems we place ourselves in relationships to others, which
then make it possible to manipulate or monetise both parties, and the
relationship itself.’^18^ These relations can be between peers at the
horizontal level but also at a vertical level between institutions and
people. Therefore, if one is to think about data, can one also consider
how data does not just affect individual autonomy but also creates
social inequality?

This brings us to the question of thinking about the concept of
access.^19^ If we are interested in thinking about access to data, it
becomes important to unpack alternative visions of what access to such
data can mean.^20^ To make access not just something that is provided
but something that is also meaningful, a useful starting point is to
consider the pathways to access that people take.^21^ Aligned to this is
to consider that there are different reasons for which data access is
required. Whereas we have discussed different meanings of data, we also
argue that it is important to ascertain – data access for what?

The motivation(s) behind access can result in different manifestations,
such as ‘public access’ where it is meant for consumption by the public
and in the public interest; ‘regulator access’ where institutions
require it in order to fulfil a bureaucratic function; ‘research access’
where it is necessary to be able to study the effects of digitally
intermediated phenomenon; and ‘corporate access’ for pursuing of
economic objectives. Looking at these different actors demonstrates how
varied the purposes of data access can be.^22^ At one level, an obvious
intention of creating better data access is to ensure that there is
greater transparency and accountability, notably of online platforms,
for instance, such that one can understand the ways in which they
function and operate. But at another level, the purposes are much
broader, and entirely subjective, depending on who the person claiming
access is. In this way, it is relational, and contextual, and emerges
within the location of those making claims.^23^

In the context of this volume, we are interested in exploring data
access for research in particular. Research is often defined as a
systematic and scientific exercise to study phenomena. It results in the
creation of new understandings of existing knowledge or in the creation
of new knowledge on its own. The role of a researcher in carrying out
such an enquiry is often bound by the constraints of a particular
discipline, where scientific rigour becomes a necessary condition to
what research is seen as appropriate or valid. However, as decolonial
scholars have repeatedly argued, the construction of who a researcher
is, and what is valid research, is a function of the political economy
of knowledge and knowledge-producing institutions.^24^ For several
years, the conditions of successful research are embedded in a
Eurocentrism, where an othering takes places of people and contexts
outside the core of the West.^25^ This is an important consideration to
keep in mind, even while we see the emergence of new regulations to
facilitate data access to research digital infrastructures.

In thinking about the effects of data access on knowledge production, it
is necessary to examine the bundle of rights that are affected because
of a denial of data access.^26^ For instance, constraints to data access
not only limit one’s capacity to know and understand but it also affect
the capacity and ability to participate and act. This is because data
becomes a currency to make things knowable and countable. It is used as
the predominant medium to describe phenomena, and thereby to make things
commensurable.^27^ Not engaging through this language therefore limits
the agency and autonomy of people, whether individuals or groups, to
take actions which are in their interest.

A second aspect in relation to data access is to examine who has the
capacity to make sense of the data once access is provided. For access
to be meaningful, it also requires the technical know-how to be able to
make sense of the data. Consequently, we see an emergence of power
hierarchies in terms of not only the form of data that is being made
available but also the emergence of those that then act as interpreters,
interlocutors, and potentially gatekeepers of the knowledge of the data.
In this regard, those that have data access become critical in terms of
not just holding knowledge but also determining the governance of
data.^28^

A third consequence of such an approach is about narratives around
data.^29^ This means that how they are interpreted, deployed, and
actioned will depend on who controls not only their access but also
their interpretation. As a consequence, it becomes imperative to examine
who draws the ‘abyssal line’ between what is considered important,
critical, and valid and what is consigned to an abyss and deemed
irrelevant.^30^

## The Academic Data Gaze

The debate on (academic) researchers’ claim to data in, and about,
digital infrastructures reveals deeper questions on the politics and
economy of knowledge production. Underlying the growing efforts to
improve researchers’ access to data in the digital society is a strong
normative assumption that such access (and data) is generally
beneficial. While we certainly sympathize with many such efforts, we
believe it is important to critically engage with these underlying
assumptions of the impacts of data access by also locating it in the
political economy around it. Failing to do so may render academia
complicit in a variety of problematic dimensions of digital technology
and, in particular, its extractivist practices. Moreover, it may amplify
a number of issues already inherent to dominant academic research
practices, including the Matthew effect. For the purposes of this
introductory chapter, we try to condense some of these issues into the
notion of the ‘academic data gaze’.

The academic data gaze can be situated along a long trajectory of the
hegemony of mainly Western academic research and its underlying logics.
The term builds on the concept of the *data gaze* as theorized by David
Beer: ‘a concept that targets an understanding of the connections,
structures, and performances of power within \[data\] analytics.… This
data gaze, and the discourse that facilitates and informs it, is
suggestive of how lives are viewed differently through data – in ever
more forensic, strategic, predictive, and knowing ways.’^31^
Importantly, we believe the data gaze is fundamentally intertwined with
modern-day forms of (for example, platform,^32^ informational,^33^ and
surveillance^34^) capitalism and its deeply extractive logics. It
acknowledges that data is not a natural element to be observed, but
always artificially produced for specific goals in the eyes of the
beholder.

Despite the much-acknowledged critique that ‘raw data is an
oxymoron’,^35^ (digital) data is increasingly seen as the main source of
valid ‘evidence’ in dominant research methods.^36^ This may not come as
a surprise considering the broader fetishization of ‘big data’ in
(Euro-American) academia as well as its benefactors in the public and
private sectors. Researchers’ calls for improved data access therefore
cannot be detached from questioning the politics of *knowledge*
production more broadly. This means recognizing that knowledge is
‘socially constructed, and historically situated’, rationalized through
research methodologies that are in themselves ‘historically produced
social formations articulated through particular discourses and systems
of signification’.^37^

By prefixing *academic* to the *data gaze*, we wish to emphasize the
complicity of academia in establishing the ‘data imaginary’ as a
dominant paradigm structuring contemporary societies. The *data
imaginary* determines what is rendered (in)visible in data-led
processes, ordering, and governance.^38^ And while its risks and
constraints have been amply debated in scholarship,^39^ datafication
processes have developed into constitutive elements of modern-day
knowledge production.^40^ In other words, we believe academia’s growing
adoption of data driven research methods has significant political
economic reverberations. It lends further legitimacy to the data gaze’s
salient claims to objectivity, neutrality, rationality, and
universality.^41^ Yet it often forgoes how ever-expanding processes of
metrification, extraction, and abstraction deprioritize or invisibilize
certain modes of knowledge (production), reinforce a variety of power
dynamics, and may even cause harm.^42^

Through her work on ‘missing datasets’, academic and artist Mimi Ọnụọha
cogently explains the important blind spots of the data imaginary.^43^
First, those with the resources to produce or collect certain data often
lack the incentives to do so (for example, law enforcement and military
operations are some of the most data-driven public sectors, yet there is
disproportionately little systematic data collected about police
brutality and military abuse). Second, the data imaginary only allows
for collecting things that fit its modes of collection, that is, through
quantification and datafication processes (for example, some things may
resist simple datafication, such as emotions or institutional racism).
Third, the act of datafication may involve more effort or resources then
the perceived benefits of datafication (for example, the benefit of
reporting sexual harassment is often perceived lower than the cost of
the process). Fourth, there might also be advantages to non-datafication
(for example, protection of situationally disadvantaged groups). Ọnụọha
reminds us that data will not solve all problems or scientific
inquiries, and this is a good thing, especially as we may risk
reductionism based on the choices made in collecting, ordering, and
labelling data.

Even so, it is increasingly recognized that surveillance and
datafication processes – often (co-)constituted and adopted by academia
– have very problematic roots indeed:^44^ from oppressive and racist
regimes underpinning slavery^45^ and Nazi Germany^46^ to the persecution
of black and brown people in the US,^47^ as well as centuries of
colonial extractivist practices more broadly.^48^ Scientific research
has played a crucial role in enabling and validating these regimes,
reproducing social hierarchies.^49^ In the digital context, pioneering
anthropologist and science and technology studies scholar Diane Forsythe
already established the sexism and silencing of voices in artificial
intelligence (AI) development in the 1990s.^50^ This historical
trajectory of both science and datafication processes cannot simply be
ignored and should actively factor into a constant self-reflective
praxis.

More recently, an important strand of critique of the academic data gaze
in the social sciences relates to so-called easy-data scholarship. Jean
Burgess and Axel Bruns, for example, explain how social media platforms
(deliberately) affect research agendas through their technical
design.^51^ Twitter (now X) in particular has proven to be the ‘most
(over-) studied social media platform precisely because it offers
relatively open data access.… Yet, the non-randomness of data captured
via these APIs \[application programming interfaces\] means that, even
in the best of times, many Twitter studies have drawn conclusions based
on substantially biased inferences.’^52^ This is not to say that all
studies using ‘easy data’ are necessarily reductionist or
unrepresentative,^53^ but it is a reminder to acknowledge how the
academic data gaze is shaped by the socio-economic conditions in which
it occurs. New and upcoming legal frameworks will only amplify these
external influences on academia’s data imaginary, especially in light of
how transparency and data access requirements will be interpreted,
operationalized, and enforced. Again, this raises questions on what
information and research are prioritized/ invisibilized and on
agenda-setting power more broadly.^54^

Ironically, the ample critique (often coming from academia) on the
public and private sectors’ embrace of data-driven processes and the
numerous issues it presents has not prevented many academic disciplines
from going down the same path. All too often ‘more data’ is
automatically seen as leading to ‘better research outcomes’, without a
clear sense of what those outcomes ought to be in the first place or a
reflection on alternative research methodologies.^55^ This entails
deeper questions on the merits, integrity, and ethics of academic
research that we cannot tackle here. At the very least, there is a
serious need for individual and collective self-reflection on questions
relating to data-driven research methods and disciplines: when they are
exploitative; what their blind spots are; how they relate to similar
processes in industry or government; and how they affect structural
inequalities, injustice, and power.^56^ Academia must confront its
‘epistemology of ignorance’ – that is, academia’s ignorance of its own
processes of reproduction – and continuously reflect on the emergence
and use of dominant research methodologies.^57^

In sum, the academic data gaze is ever-expanding and does not tolerate
alternative means of knowledge production.^58^ Its internal logics and
outcomes are presented as indisputable truths. As such, academia is
constitutive of dominant *data assemblages*, described by Rob Kitchin as
complex socio-technical systems involving a multitude of actors and
processes pursuing the production of data.^59^ That is why claims more
and better data access should be accompanied by critical inquiries into
the underlying logics and rationales of data processes and their
agenda-setting power. How, and at what expense, do legal data access
frameworks and data-driven research methods reinforce or construct
specific frames of truth and knowledge?^60^ We see this volume as
contributing to this vital broader discussion that we need to have on
academic claims to researcher data access and the power dynamics it
entails.

## Power Dynamics in Data Access for Research

In this subsection, we explore some of the complex power dynamics
underlying researcher data access debates. The incremental invasion of
digital infrastructures into every part of society has accelerated the
accumulation of power and established new forms of data-driven power
asymmetries. A quintessential example of this is the emergence of online
platforms as dominant actors in today’s information society and the
focal point of many new legal frameworks.

The rise of platform power manifests primarily through the operational
control that vests with Big Tech companies because of their dominance
over computational infrastructures.^61^ This control over infrastructure
emerges in terms of determining which parts of the world can be made
visible or legible through providing data access, what values and ideas
must be given prominence in governance or policy settings, and how
private–public relationships are being reshaped through increased
dependency on Big Tech.^62^

Power takes on different forms. There is a technical power by virtue of
platforms determining how one can operate within them or in relation to
them. This technical power, however, does not operate on its own,
because of their infrastructural power to also lobby for self-regulation
and, in turn, reshape governance practices. In doing so, technical power
gives way to shaping how sectors are being managed. Consider the case of
the Oversight Board, which is an entity set up by Meta to decide on
matters related to content on its platforms, including Facebook and
Instagram. This is an example where an attempt is made to propose a
regulatory architecture that informs how to uphold the right to freedom
of expression online. However, as Chinmayi Arun has argued, Meta
operates differently in different jurisdictions, engaging flexibly when
it deals with states and publics that do not have the regulatory
capacity to push back, and therefore ensuring that content moderation
has different approaches depending on location.^63^ This is relevant
because it demonstrates the power that platforms have to mediate between
different political and economic entities. More often than not, where it
is to their economic benefit to side with states, over people, it is
willing to make compromises. WhatsApp, for instance, attempted to change
its privacy policy all over the world: whereas in the EU data would be
shared only for WhatsApp’s purposes, in non-EU regions it could also be
used for other Meta companies.^64^

This example demonstrates that along with computational power,
regulatory power is mediated by the power of transnational markets, the
capacity of institutions to be able to push back, as well as a societal
power and awareness about the possibilities of alternative
platforms.^65^ For instance, Europe, despite priding itself on being at
the forefront of tech regulation, has had innumerable challenges with
implementation and enforcement. Ireland, which plays a vital role as a
data protection regulator in the EU, recently proposed a law that
renders confidential all matters before the data protection
commissioner. This undertaking, as Amnesty International has argued, is
a ‘blatant attempt not only to shield Big Tech from scrutiny but also to
silence individuals and organizations that stand up for the right to
privacy and data protection’.^66^

These decisions by states in turn determine how regulation is perceived
and what the capacity of civil society (including academia) is to
engage, challenge, and resist. Platform power has increasingly affected
the independence of academia which has long been complicit with
accepting funding from corporations, including fossil fuel companies and
those engaging in surveillance, without the necessary safeguards or
institutional mechanisms to ensure transparency and accountability. A
recent report of De Jonge Akademie in the Netherlands argues that there
is a need for a greater overview of funding flows and how such funding
affects researchers, what are the risks at play of accepting such
funding while, at the same time, ensuring that institutions have the
capacity to be able to report as well as audit funding
relationships.^67^

Another telling example of platform power comes from the ongoing
genocide in Palestinian territories.^68^ On 27 October 2023, Israel cut
access to phone and internet services for 34 hours, leaving a majority
of over two million Palestinians who live in Gaza as well as aid
organizations on the ground with no way to connect to the outside
world.^69^ It is a move that Israel has since used multiple times as a
deliberate strategy, in particular before a military operation. The
situation was so dire that, with no alternatives in sight, people
appealed to Elon Musk who owns Starlink – a satellite internet venture –
to provide internet.^70^ This is not the only case. In Ukraine, during
the ongoing war with Russia, Musk was asked by the Ukrainian authorities
to provide Starlink as a service to keep people online in case the
internet infrastructure was destroyed, which he did.^71^ However, over
the course of the conflict, Musk has variously threatened to withdraw
access, at times stating that he cannot fund it, while at other moments
making grand claims that, regardless of the financial situation of
Starlink, he will keep Ukrainians online.^72^ The absurdity that the
only way for millions of besieged people to have internet access is
through appealing to one person’s largesse demonstrates the dangers that
will emerge because of private corporations having control over critical
infrastructures.^73^

As this example demonstrates, this is not just technical power but power
that manifests in terms of informational power, determining what
narratives will be heard and what will be erased.^74^ It is an
institutional power because it intrinsically influences how emergency
teams will be able to respond, ask for help, and document atrocities
being committed. It is also societal power, shaping the ways in which
people will know about these crises and how they make sense of their
role in such a situation.

The criticality of data access is even more apparent in the Palestinian
context, when the former president of the United States (US), despite
the vast amount of verified images and video material showing shocking
amounts of human and material devastation, said, ‘I have no notion that
Palestinians are telling the truth about how many people are
killed.’^75^ As Hala Alyan, a Palestinian American author states, this
statement was made knowing the power that it would have: ‘It would
quietly cleverly, delegitimize the dead. Even the dead. He said it and
the saying was erasure.’ She goes on to say, ‘What counteracts erasure?
Witnessing’, going on to show how a report was then released by the
Palestinian Ministry of Health with 7,028 names, of which 2,913 were
children.^76^ At the time of finalizing this volume, the confirmed death
toll stood at 34,367, of which more than 13,800 were children and over
100 were journalists.^77^

Witnessing is a critical component to counteracting the power of
platforms. It is a fundamental component of access. Access is not
passive; it is an opportunity to be able to challenge structures of
power that constitute how platforms are designed and imagined. Having
data access allows one to be able to understand what data is being
collected, recorded, labelled, and a consequence distributed to offer
provides perspective in terms of what information can be considered
valid and which must be disregarded – an epistemic choice, which is used
to silence those who are already oppressed.^78^ As Omar Suleiman writes,

> Open Apple, Google, or any other digital map. Type ‘Palestine’. You
> won’t find it. You will only find Israel. If you’re lucky, you may be
> directed to a small patchwork of what is called ‘Palestinian
> Territories’ firmly embedded inside Israel lest anyone mistakenly
> think it is an independent nation-state. And of course, you will find
> nowhere on any map the keyword that precedes Palestinian Territories
> to lay bare the ugly, but necessary and harrowing truth:
> ‘Occupied’.^79^

This is but one example of how we are witness to the ways in which
platforms construct identities, legitimize versions of history, and
dominate the lenses through which we are to view the world. Palestinian
erasure is continually supported by platforms with accusations of shadow
bans and blocking of several pro-Palestinian accounts.^80^ It would be
complete without the challenge to platforms by Palestinian people and
others across the world who must subvert platforms by interspersing
content on dispossession of lands, homes, and people with humour, and
the like, completely unrelated to the conflict.

This is where witnessing is also important to challenge the epistemic
power of platforms. This power, to draw from Miranda Fricker, can
manifest in terms of who has the power to bear testimony (testimonial
power), and whether their words are believed and acted upon, and a
hermeneutical power where people’s capacities to understand themselves
are impacted because of being denied the vocabulary to voice their
experiences.^81^ This power does not emerge in a vacuum but is deeply
embedded in the political economy of where platforms operate and what
regulatory power they seek to influence, or abide by. Numerous incidents
in the past have shown that platforms such as Zoom have actively
participated in censoring different voices. Through regulation such as
anti-terrorism laws, it has sought to prevent Palestinian activists from
speaking on university campuses. In China, it has been accused of
violating its own policies to censor discussions about Tiananmen Square
at the Chinese government’s request.^82^ Social platforms not only
thereby become gatekeepers to knowledge but also supersede the expertise
housed within different domains such as academia to make such
decisions.^83^

In these different attempts to constrain access to digital
infrastructures, the consequences are significant. This is because these
platforms’ power not only comes from determining who gets to see what,
but also from their infrastructural power and how they prevent anyone
from observing their scale or operations, such as the logics for which
posts get censored, shadow-banned, or removed. It is these complex and
multidimensional power dynamics that ought to be factored into any
(policy) debate on researcher access to data.

This volume brings together 8 different chapters within the theme of
researchers’ access to data in and about digital infrastructures. The
collection of chapters also demonstrates the wide variety of angles and
issues involved when it comes to the governance and regulation of data
access for research. Because of this diversity in angles, the chapters
are distributed along three main parts: imaginations, limitations, and
promises.

### Imaginations 

We do not take the contours of what data access is to be a given.
Instead, we recognize that what it is and how it is understood are
unique in the different chapters in this volume. The chapters in this
part offer distinct imaginations of data access by exploring its
relationship to research and, as a result, also adjacent issues related
to governance, autonomy, rights, and practice. In chapter 2,
‘Re-Conceptualizing Governance Policies on Data Access for Research’,
Carolina Aguerre helps us make sense of the plethora of national and
international approaches to govern data access (for research), taking a
polycentric governance lens. Her analysis reaches beyond traditional
Euro-American perspectives, highlighting majority-of-the-world angles on
two specific policy arenas: open science and AI strategies. The
following chapter, ‘Violent Plains’, by Frank Kwaku Agyei, Lawrence
Kwabena Brobbey, Paul Osei-Tutu, and Boateng Kyereh, pushes our
imagination even further, exploring challenges and strategies for access
to pastoralists’ data in Ghana. It offers a very concrete and gripping
account of the many issues underlying the collection of data about
(groups of) individuals in the first place. We see the chapter as an
invitation to the academic community to self-reflect on over-reliance on
available data, what is invisibilized, as well as various assumptions
about data quality and universality.

Through these different imaginations, the chapters in this part
challenge us to think of ways of describing, categorizing, and
institutionalizing what researchers can do in different contexts. The
last chapter in this part also demonstrates this quite well. In chapter
4, ‘From Rights to Skills’, Midas Nouwens reflects on data access rights
in relation to their role as an educator in higher education. Based on
their teaching experiences, they propose a variety of ways for students
to work with and critically reflect on data access rights, helping them
to navigate and co-shape digital societies.

In sum, the imaginations presented in the first part of the volume
highlight multifarious aspects of the debate around data access in
academic contexts. They invite us to reflect on who owes data access on
the one hand and who is owed data access on the other. They help discuss
the political economies within which such relations are created, the
challenges of enabling and sustaining such access, and who benefits as a
result of such data access, and they do so at different scales – from
local in focus to transnational in scale – as well as speak to different
epistemic communities such as universities, transnational organizations,
pastoralists, and regulators.

### Limitations

Critical to our understanding of data access is the reality that just
providing such access is insufficient. Access requires an enabling
environment where people have the capacity, resources, skills, and time
to use such access to achieve desirable outcomes. This part of the
volume discusses various challenges both to the EU conceptualization of
data access rights and more generally in terms of the challenges of
researching digital platforms and infrastructures. It explores across
contexts, both jurisdictional as well as domain-wide, how using data
access for accountability and transparency requires more than just
access rights and instead requires institutional capacity. Such capacity
oftentimes is not available in academic and civil society institutions,
and the chapters caution us whether access rights create dependencies on
actors who do not have the capacity to be able to make use of the
rights.

Chapter 5 looks at transparency and data access in the context of
accountability of public authorities, specifically law enforcement and
intelligence agencies. André Ramiro, Pedro Amaral, and Marcos César M.
Pereira in chapter 6, ‘Keys Thrown Away?’, reflect on their own
experience of conducting an empirical research project involving the
strategic use of freedom of information laws in Brazil. This
self-reflective study exposes important limitations to research into
government surveillance infrastructures, through convoluted claims to
secrecy. As such, the chapter also shows us the dangers of
‘pretend-transparency’ for democratic oversight.

While chapter 5 focuses on how researchers relate to accountability and
democratic oversight dimensions of data access rules, the following
chapter zooms in on the market-driven aspects of these rules. Chapter 6,
‘Digging into the EU Data Laws and Their Impact on African Researchers’,
by Paul Esselaar, explains the EU internal market focus of many new
provisions, at the expense of researchers, especially those based
outside the EU. Exploring the issues and constraints of a whole raft of
new EU data access provisions, specifically in relation to African
researchers, Esselaar reveals a darker side of the EU’s extraterritorial
reach and the potentially perverse effects of these rules on data and
research originating in the African continent.

## Promises

In the last part of the volume, we are interested in unpacking various
promises that emerge because of providing data access for research. The
dominant presumption with data access is that it will have beneficial
consequences for increased transparency, oversight, and accountability
to the wider publics, especially when it comes to online platforms. As a
result, such access would not only challenge informational asymmetries
but also encourage more a meaningful understanding of, and participation
in, the digital society. That also appears in much of the debate
surrounding the barrage of new policy frameworks tackling the data
economy. The chapters in this part take a closer look at different EU
policy initiatives involving transparency and data access provisions.
While hopeful in their outlook, the authors in these chapters also
provide necessary nuance to policymakers’ claims. Importantly, they help
us think through important issues and pitfalls, tracing concrete methods
and practices for overcoming them.

Chapter 7, ‘A Subject Access Request, Then What?’ by Jake Stein and
Reuben Binns, does so by zooming in on data access promises in the
context of platform workers. The chapter draws on participatory action
research, incorporating legal and technical insights, to build a data
architecture for platform worker empowerment. The authors are driven by
an aspiration to design public-service data infrastructures, tackling
hard questions on how workers, researchers, or other
public-interest-driven groups may confront data structures that are
imposed by powerful actors such as platform companies. In light of new
and upcoming transparency requirements, notably in the EU, Stein and
Binns turn the discussion towards lowering the barriers to data
analytics for advocates in low-resource environments and propose a
lightweight, queryable data institution which relies on existing
open-source, unstructured data analytics infrastructures. Such data
institutions form the focal point of the next chapter: chapter 8, ‘Data
Intermediaries for Good’, in which Matteo Nebbiai zooms in on the
emergence of a particular type of data institution that emerged as a new
legal category of actors in the EU’s Data Governance Act (DGA).
So-called data intermediation services are hailed by the legislator as
enabling data sharing between an undetermined number of data holders and
users. Through a systematic analysis of 54 already existing data
intermediary services, Nebbiai explores to what extent these actors also
contribute to better access for research in particular.

The next chapter takes a closer look at questions of researcher data
access in the online platform context. Chapter 9, ‘From Discretion to
Obligation?’ by Michalina Kowala, traces the legislative development of
the EU’s 2018 and 2022 codes of practice on disinformation. Kowala
autoethnographically identifies the key issues and shortcomings of
researcher data access provisions in the code(s). As such, the chapter
demonstrates the gap between theory and praxis when it comes to
regulating data access for research, in a very concrete context.

In sum, this part offers various ways in which the promises of data
access regulation can be operationalized, for instance, by framing such
access as a right to ensure that there are guarantees, but also by
creating new institutional frameworks to encourage participation and
collaborative communities for research. This part therefore provides
pathways with which the goals and values associated with data access can
be realized.

\*\*\*

Finally, we hope this volume may provoke and incite readers to consider
the many dimensions of researcher data access. Recent policy discussions
have lauded the potential of the data economy, with little attention to
deeper questions relating to data access in non-economic contexts or to
broader political economy implications and shifting power dynamics. In
this introductory chapter, we aimed to lift the veil on some of these
broader issues that merit more attention. Notably, what are the
underlying assumptions of ‘access’ and how does it inform how we think
about data access in research contexts? How may academia – from the
individual to the institutional levels – be complicit in structures of
power and oppression? And what do these structures look like in the
first place? As such, this chapter invites you, the reader, to reflect
on your own positionality in relation to existing data access claims as
well. We believe this to be a great starting point to peruse through the
chapters in this book. Rather than giving a coherent or comprehensive
account of the debate – which we do not deem possible in the first
place! – the chapters expose us to very diverse perspectives and
approaches: from the specific to the general, the local to the
international, technical to legal, doctrinal to empirical. May they
inspire you in your own academic practice.

### Notes

1.  See Axel Bruns, ‘After the “APIcalypse”: Social Media Platforms and
    Their Fight against Critical Scholarly Research’, *Information,
    Communication and Society* 22, no. 11 (19 September 2019):
    1544–1566; Daphne Keller and Paddy Leerssen, ‘Facts and Where to
    Find Them: Empirical Research on Internet Platforms and Content
    Moderation’, in *Social Media and Democracy: The State of the Field
    and Prospects for Reform*, ed. N. Persily and J. Tucker, 220–251
    (Cambridge University Press, 2020); Jef Ausloos, Paddy Leerssen, and
    Pim ten Thije, *Operationalizing Research Access in Platform
    Governance: What to Learn from Other Industries?* (Algoritm Watch,
    2020); Eszter Hargittai, *Research Exposed: How Empirical Social
    Science Gets Done in the Digital Age* (Columbia University Press,
    2021).

2.  For a detailed overview of transparency and data access provisions
    in recent EU ‘data law’, see Jef Ausloos, Arlette Meiring, Doris
    Buijs, Mireille van Eechoud, Stefanie Boss, and Joanna Strycharz,
    *Information Law and the Digital Transformation of the University*,
    pt 2: *Access to Data for Research*, 15 September 2023 (Institute
    for Information Law, University of Amsterdam),
    https://www.uva.nl/en/about-the-uva/policy-and-regulations/
    general/preserving-digital-sovereignty-of-universities-and-researchers/
    preserving-digital-sovereignty-of-universities-and-researchers.html
    (27 November 2024).

3.  See, in this regard, also Celine-Marie Pascale, ‘Epistemology and
    the Politics of Knowledge’, *Sociological Review* 154, no. 58
    (2010): 154–165, 163.

4.  Diana E. Forsythe and David J. Hess, *Studying Those Who Study Us:
    An Anthropologist in the World of Artificial Intelligence* (Stanford
    University Press, 2001), xix.

5.  Joan Lopez Solano, Aaron Martin, Siddharth de Souza, and Linnet
    Taylor, *Governing Data and Artificial Intelligence for All: Models
    for Sustainable and Just Data Governance* (European Parliament,
    2022); Amber Sinha and Arindrajit Basu, ‘Why Metaphors for Data
    Matter’, Bot Populi, 13 August 2021,
    https://botpopuli.net/?post\_type=post&p=4069 (accessed 11 September
    2023).

6.  Nadezhda Purtova and Gijs van Maanen, ‘Data as an Economic Good,
    Data as a Commons, and Data Governance’, arXiv, 18 April 2023,
    http://arxiv. org/abs/2212.10244 (accessed 15 November 2023); Anita
    Gurumurthy and Nandini Chami, ‘Governing the Resource of Data: To
    What End and for Whom? Conceptual Building Blocks of a Semi-Commons
    Approach’, Data Governance Network Working Paper 23, 2022,
    https://itforchange.net/sites/
    default/files/1741/WP23-Governing-the-Resource-of-Data-AG-NC.pdf
    (accessed 19 December 2024).

7.  Solano, Martin, de Souza, and Taylor, *Governing Data and Artificial
    *

> *Intelligence for All*.

1.  Tahu Kukutai and John Taylor, *Indigenous Data Sovereignty: Toward
    an Agenda* (ANU Press, 2016).

2.  Stephanie Russo Carroll, Ibrahim Garba, Oscar L. Figueroa-Rodríguez,
    Jarita Holbrook, Raymond Lovett, Simeon Materechera, Mark Parsons,
    Kay Raseroka, Desi Rodriguez-Lonebear, Robyn Rowe, Rodrigo Sara,
    Jennifer D. Walker, Jane Anderson, and Maui Hudson, ‘The CARE
    Principles for Indigenous Data Governance’, *Data Science Journal*
    43, no. 19 (2020) 1–12, DOI: https://doi.org/10.5334/dsj-2020-043.

3.  Tahu Kukutai, ‘Indigenous Data Sovereignty: A New Take on an Old
    Theme’,

> *Science* 382, no. 6674, DOI: 10.1126/science.adl4664.

1.  We Are Not Numbers, ‘About’, https://wearenotnumbers.org/about
    (accessed 15 November 2023).

2.  Yuval Abaraham discusses how artificial intelligence (AI) is being
    used to identify assassination targets amongst people in Gaza, with
    little human oversight, creating a mass killing machine. Yuval
    Abraham, ‘“Lavender”: The AI Machine Directing Israel’s Bombing
    Spree in Gaza’, *+972 Magazine*, 3 April 2024,
    https://www.972mag.com/lavender-ai-israeli-army-gaza (accessed 12
    May 2024).

3.  Lisa Gitelman, *‘Raw Data’ Is an Oxymoron* (MIT Press, 2013).

4.  Julian Alberto Posada Gutierrez, ‘The Coloniality of Data Work:
    Power and Inequality in Outsourced Data Production for Machine
    Learning’, thesis, University of Toronto, November 2022,
    https://tspace.library.utoronto.ca/ handle/1807/126388 (accessed 9
    October 2023).

5.  Billy Perrigo, ‘OpenAI Used Kenyan Workers on Less than \$2 Per
    Hour: Exclusive’, *Time*, 18 January 2023,
    https://time.com/6247678/openaichatgpt-kenya-workers (accessed 8
    August 2023).

6.  Birgitta Bergvall-Kåreborn and Debra Howcroft, ‘Amazon Mechanical
    Turk and the Commodification of Labour’ *New Technology, Work and
    Employment* 213, no. 29 (2014): 213–223.

7.  Linnet Taylor, Luciano Floridi and Bart van der Sloot (eds.), *Group
    Privacy: New Challenges of Data Technologies* (Springer
    International Publishing, 2017).

8.  Salome Viljoen, ‘A Relational Theory of Data Governance’, SSRN
    Scholarly Paper ID 3727562, Social Science Research Network,
    https://papers.ssrn. com/abstract=3727562 (accessed 19 October
    2021).

9.  Daniel M. Brinks, ‘Access to What? Legal Agency and Access to
    Justice for Indigenous Peoples in Latin America’, *Journal of
    Development Studies* 348, no. 55 (2019): 348–365; Siddharth Peter de
    Souza, ‘A Capability Approach to Access to Justice in Plural Legal
    Systems’, in *Designing Indicators for a Plural Legal World*, by
    Siddharth Peter de Souza, 164–203 (Cambridge University Press,
    2022).

10. Miranda Fricker, ‘Introduction’, in *Epistemic Injustice: Power and
    the Ethics of Knowing*, by Miranda Fricker, 1–8 (Oxford University
    Press, 2007); Sabelo J. Ndlovu-Gatsheni, ‘Introduction: Seek Ye
    Epistemic Freedom First’, in *Epistemic Freedom in Africa*, by
    Sabelo J. Ndlovu-Gatsheni, 1–41 (Routledge 2018).

11. Hazel Genn, ‘The Landscape of Justiciable Problems’, in *Paths to
    Justice: What People Do and Think about Going to Law*, by Hazel Genn
    and Sarah Beinart, 21–66 (Hart Publishing, 1999); Pascoe Pleasence,
    Nigel Balmer, and Rebecca Sandefur, ‘Paths to Justice: A Past,
    Present and Future Roadmap’, Nuffield Foundation, 2013,
    https://www.nuffieldfoundation.org/sites/
    default/files/files/PTJ%20Roadmap%20NUFFIELD%20Published.pdf
    (accessed 19 December 2024).

12. See, for example, Ausloos, Meiring, Buijs, van Eechoud, Boss, and
    Strycharz*, Information Law and the Digital Transformation of the
    University*, pt 2: *Access to Data for Research*.

13. Jef Ausloos and Pierre Dewitte, ‘Shattering One-Way Mirrors: Data
    Subject Access Rights in Practice’, *International Data Privacy Law*
    4, no. 8 (2018): 4–28; René Mahieu, Jef Ausloos, and Michael Veale,
    ‘Getting Data Subject Rights Right’, LawArXiv, 2019, preprint,
    https://osf.io/e2thg (accessed 15 November 2023).

14. Linda Tuhiwai Smith, ‘Introduction’, in *Decolonizing Methodologies:
    Research and Indigenous Peoples*, by Linda Tuhiwai Smith, 1–18 (ZED
    Books 2012).

15. Edward W. Said, *Orientalism* (Knopf Doubleday, 2014).

16. Amartya Sen, *The Idea of Justice* (Harvard University Press, 2011);
    Amartya Sen, ‘Human Rights and Capabilities’, *Journal of Human
    Development* 151, no. 6 (2005): 151–166.

17. Wendy Nelson Espeland and Mitchell L. Stevens, ‘Commensuration as a
    Social Process’, *Annual Review of Sociology* 313, no. 24 (1998):
    313–343;

> Sally Engle Merry, *The Seductions of Quantification: Measuring Human
> Rights, Gender Violence, and Sex Trafficking* (University of Chicago
> Press, 2016); Siddharth Peter de Souza, ‘“Meanings”, “Trust” and
> “Power”: Critical Perspectives on Legal Indicators’, in *Designing
> Indicators for a Plural Legal World*, by Siddharth Peter de Souza,
> 20–50 (Cambridge University Press, 2022).

1.  Sally Engle Merry, ‘Measuring the World: Indicators, Human Rights,
    and Global Governance’, *Current Anthropology* S83, no. 52 (2011):
    S83–S95.

2.  Wendy Espeland, ‘Narrating Numbers’, in *The World of Indicators:
    The Making of Governmental Knowledge through Quantification*, ed.
    Richard Rottenburg, Sally E. Merry, Sung-Joon Park, and Johanna
    Mugler, 56–75 (Cambridge University Press, 2015).

3.  Boaventura de Sousa Santos, ‘Introduction: Why the Epistemologies of
    the South? Artisanal Paths for Artisanal Futures’, in *The End of
    the Cognitive Empire:The Coming of Age of Epistemologies of the
    South*, by Boaventura de Sousa Santos, 1–16 (Duke University Press,
    2018).

4.  David Beer, *The Data Gaze: Capitalism, Power and Perception* (Sage
    Publishing, 2019).

5.  Nick Srnicek, *Platform Capitalism* (John Wiley & Sons, 2017).

6.  Julie E. Cohen, *Between Truth and Power: The Legal Constructions of
    Informational Capitalism* (Oxford University Press, 2019).

7.  Shoshana Zuboff, *The Age of Surveillance Capitalism: The Fight for
    a Human Future at the New Frontier of Power* (Profile Books, 2019).

8.  Gitelman,*‘Raw Data’ is an Oxymoron*; Rob Kitchin and Tracey
    Lauriault, ‘Towards Critical Data Studies: Charting and Unpacking
    Data Assemblages and Their Work’, in *Thinking Big Data in
    Geography*, ed. J. Thatcher, J. Eckert, and A. Shears, 3–20
    (University of Nebraska Press, 2018).

9.  Pascale, ‘Epistemology and the Politics of Knowledge’, 154, 157.

10. Pascale, ‘Epistemology and the Politics of Knowledge’, 163. See also
    Linda Tuhiwai Smith, *Decolonizing Methodologies: Research and
    Indigenous Peoples* (Bloomsbury Academic, 2023).

11. Beer, *The Data Gaze.*

12. See ample references in Rob Kitchin, *The Data Revolution: Big Data,
    Open Data, Data Infrastructures and Their Consequences* (Sage
    Publishing, 2014); Safiya Umoja Noble, *Algorithms of Oppression:
    How Search Engines Reinforce Racism* (NYU Press, 2018); Virginia
    Eubanks, *Automating Inequality: How High-Tech Tools Profile,
    Police, and Punish the Poor* (St Martin’s Press, 2018); Andreas
    Hepp, Juliane Jarke, and Leif Kramp, ‘New Perspectives in Critical
    Data Studies: The Ambivalences of Data Power—An Introduction’, in
    *New Perspectives in Critical Data Studies: The Ambivalences of Data
    Power*, ed. Andreas Hepp, Juliane Jarke, and Leif Kramp (Springer
    International Publishing, 2022).

13. See, for example, Bernhard Rieder and Theo Röhle, ‘Digital Methods:
    Five Challenges’, in *Understanding Digital Humanities*, ed.
    David M. Berry, 67–84 (Palgrave Macmillan, 2012).

14. Stefania Milan and Emiliano Treré, ‘Big Data from the South(s):
    Beyond Data Universalism, Television and New Media’, *Television and
    New Media* 20, no. 4, DOI: https://doi.org/10.1177/1527476419837;
    Rieder and Röhle, ‘Digital Methods’.

15. See, in this regard, also David Beer, *Metric Power* (Palgrave
    Macmillan, 2016); Kitchin and Lauriault, ‘Towards Critical Data
    Studies’, 7.

16. Mimi Ọnụọha, ‘An Overview and Exploration of the Concept of Missing
    Datasets’, GitHub, 3 February 2016, https://github.com/MimiOnuoha/
    missing-datasets (accessed 12 October 2023).

17. Meredith Whittaker, ‘Origin Stories: Plantations, Computers, and
    Industrial Control’, *Logic(s) Magazine*, 17 May 2023.

18. Caitlin Rosenthal, *Accounting for Slavery: Masters and Management*
    (Harvard University Press, 2018).

19. Edwin Black, *IBM and the Holocaust: The Strategic Alliance between
    Nazi Germany and America’s Most Powerful Corporation* (Crown
    Publishers, 2001).

20. Simone Browne, *Dark Matters: On the Surveillance of Blackness*
    (Duke University Press, 2015).

21. Donna Cormack and Tahu Kukutai, ‘Indigenous Peoples, Data, and the
    Coloniality of Surveillance’, in *New Perspectives in Critical Data
    Studies: The Ambivalences of Data Power*, ed. Andreas Hepp, Juliane
    Jarke, and Leif Kramp (Springer International Publishing, 2022),
    126–127.

22. For example, academic work on eugenics and early psychoanalysis have
    been constitutive of systemic racism and sexism across society. See
    notably Pascale, ‘Epistemology and the Politics of Knowledge’,
    154, 157. See also Smith, *Decolonizing Methodologies*.

23. Forsythe and Hess, *Studying Those Who Study Us*.

24. Jean Burgess and Axel Bruns, ‘Easy Data, Hard Data: The Politics and
    Pragmatics of Twitter Research after the Computational Turn’, in
    *Compromised Data: From Social Media to Big Data*, ed. Ganaele
    Langlois, Joanna Redden, and Greg Elmer, 93–111 (Bloomsbury
    Academic, 2015).

25. Rebekah Tromble, ‘Where Have All the Data Gone? A Critical
    Reflection on Academic Digital Research in the Post-API Age’,
    *Social Media + Society* 7 (2021): 1–18. Similarly, see Kevin
    Driscoll and Shawn Walker, ‘Working within a Black Box: Transparency
    in the Collection and Production of Big Twitter Data’,
    *International Journal of Communication* 8 (2014): 1745–1764; David
    Gunnarsson Lorentzen and Jan Nolin, ‘Approaching Completeness’,
    *Social Science Computer Review* 38 (2015): 10–24; Eszter Hargittai,
    ‘Potential Biases in Big Data: Omitted Voices on Social Media’,
    *Social Science Computer Review* (2018), DOI:
    10.1177/089443931878832; Cornelius Puschmann, ‘An End to the Wild
    West of Social Media Research: A Response to Axel Bruns’,
    *Information, Communication and Society* 22, no. 11 (2019):
    1582–1589.

26. Suay M. Özkula, Paul J. Reilly, and Jenny Hayes, ‘Easy Data, Same
    Old Platforms? A Systematic Review of Digital Activism
    Methodologies’, *Information, Communication and Society* 1, no. 15
    (2022): 1–20.

27. Beer, *The Data Gaze*.

28. See, for example, Arielle Hesse, Leland Glenna, Clare Hinrichs,
    Robert Chiles, and Carolyn Sachs, ‘Qualitative Research Ethics in
    the Big Data Era’, *American Behavioral Scientist* (2018), DOI:
    https://doi. org/10.1177/0002764218805806; Ausloos, Meiring, Buijs,
    van Eechoud, Boss, and Strycharz*, Information Law and the Digital
    Transformation of the University*, pt 2: *Access to Data for
    Research*.

29. Sebastián Lehuedé calls for *radicalizing* reflexivity in critical
    data studies in ‘The Double Helix of Data Extraction: Radicalising
    Reflexivity in Critical Data Studies’, *Technology and Regulation*
    (22 March 2024): 89–91, DOI:
    https://doi.org/10.26116/techreg.2024.009.

30. Pascale, ‘Epistemology and the Politics of Knowledge’, 154, 158. In
    the context of digital methods, see Burgess and Bruns, ‘Easy Data,
    Hard Data’. For humanities and social sciences research, see also
    the work of Bernhard Rieder and, in particular, Rieder and Röhle,
    ‘Digital Methods’.

31. See Beer, *The Data Gaze*, 220; Smith, *Decolonizing Methodologies*.

32. Kitchin, *The Data Revolution*; Kitchin and Lauriault, ‘Towards
    Critical Data Studies’, 6–7; Hepp, Jarke, and Kramp, ‘New
    Perspectives in Critical Data Studies’, 5.

33. Beer, *The Data Gaze*, ch. 1.

34. ‘Programmable Infrastructures’, TU Delft,
    https://www.tudelft.nl/tbm/ programmable-infrastructures (accessed
    29 June 2022).

35. Joan Lopez Solano, A. Martin, F. Ohai, S. P. de Souza, and I.
    Taylor, ‘Digital Disruption or Crisis Capitalism? Technology, Power
    and the Pandemic’, *Global Data Justice* (2022), DOI:
    https://doi.org/10.26116/gdj-euaifund*.*

36. Chinmayi Arun, ‘Facebook’s Faces’, 15 March 2021,
    https://papers.ssrn. com/abstract=3805210 (accessed 15 November
    2023).

37. ‘We Knew India Was Going to Be a Big Place for Signal: Brian Acton’,
    *Business Standard*, 13 January 2021,
    https://www.business-standard.com/
    article/technology/we-knew-india-was-going-to-be-a-big-place-for-signalbrian-acton-121011300189\_1.html
    (accessed 11 March 2023).

38. See the work of the Non-aligned Technologies Movement, which argues
    for why we need to pursue alternative platforms. Ulises Ali Mejias,
    ‘To Fight Data Colonialism, We Need a Non-Aligned Tech Movement’, Al
    Jazeera, 8 September 2020,
    https://www.aljazeera.com/opinions/2020/9/8/to-
    fight-data-colonialism-we-need-a-non-aligned-tech-movement (accessed
    16 April 2024).

39. ‘Ireland: Draconian Law to Make Data Protection Procedures
    Confidential’, Amnesty International, 28 June 2023,
    https://www.amnesty.org/en/latest/
    news/2023/06/ireland-draconian-law-to-make-data-protection-proceduresconfidential
    (accessed 15 November 2023).

40. ‘Space to Think: An Analysis of Structural Threats to Academic
    Freedom and Integrity’, De Jonge Akademie, 20 June 2023,
    https://www.dejongeakademie.

> nl/en/publications/2495737.aspx (accessed 15 November 2023).

1.  ‘Public Statement: Scholars Warn of Potential Genocide in Gaza’,
    *TWAILR: Third World Approaches to International Law Review*, 17
    October 2023,
    https://twailr.com/public-statement-scholars-warn-of-potential-genocide-ingaza
    (accessed 15 November 2023).

2.  Abu Bakr Bashir, Iyad Abuheweila, Vivian Nereim, and Yousur Al-Hlou,
    ‘Gaza Blackout Cut Palestinians’ Internet and Phone Service for 34
    Hours’, *New York Times*, 29 October 2023,
    https://www.nytimes.com/2023/10/29/
    world/middleeast/gaza-blackout-internet-israel.html (accessed 15
    November 2023).

3.  Priyanka Shankar, ‘Can Elon Musk’s Starlink Provide Internet Service
    to Gaza?’ Al Jazeera, 29 October 2023, https://www.aljazeera.com/
    news/2023/10/29/can-elon-musks-starlink-provide-internet-service-to-gaza
    (accessed 15 November 2023).

4.  ‘Elon Musk Activates Starlink Satellites to Give Ukraine Data
    Backup’, *Politico*, 26 February 2022,
    https://www.politico.eu/article/elon-muskactivates-starlink-satellites-to-give-ukraine-data-backup
    (accessed 17 April 2024).

5.  ‘Elon Musk U-Turns, Says Will Keep Funding Starlink in Ukraine’, Al
    Jazeera, 15 October 2022,
    https://www.aljazeera.com/news/2022/10/15/inreversal-musk-says-will-continue-funding-starlink-in-ukraine
    (accessed 17 April 2024).

6.  Adam Satariano, Scott Reinhard, Cade Metz, Sheera Frenkel, and
    Malika Khurana, ‘With Starlink, Elon Musk’s Satellite Dominance Is
    Raising Global Alarms’, *New York Times*, 28 July 2023,
    https://www.nytimes.com/
    interactive/2023/07/28/business/starlink.html (accessed 15 November
    2023).

7.  Ndlovu-Gatsheni, ‘Introduction’.

8.  ‘Biden Says He Has “No Confidence” in Palestinian Death Count’,
    Reuters, 26 October 2023,
    https://www.reuters.com/world/middle-east/biden-sayshe-has-no-confidence-palestinian-death-count-2023-10-26
    (accessed 15 November 2023).

9.  Hala Alyan on Instagram: ‘On Witnessing \[*sic*\] Second Slide Is
    from @ dianabuttu’, Instagram, 26 October 2023,
    https://www.instagram.com/p/ Cy4KUAOvkjy (accessed 15 November
    2023).

10. ‘Israel-Gaza War in Maps and Charts: Live Tracker’, Al Jazeera,
    https://www.
    aljazeera.com/news/longform/2023/10/9/israel-hamas-war-in-maps-andcharts-live-tracker
    (accessed 17 April 2024).

11. Boaventura de Sousa Santos, *Epistemologies of the South: Justice
    Against Epistemicide* (Routledge, 2015).

12. Omar Suleiman, ‘Erasing Palestine’, Al Jazeera, 19 Oct 2023,
    https:// www.aljazeera.com/opinions/2023/10/19/erasing-palestine-2
    (accessed 15 November 2023).

13. ‘Platforms Must Stop Unjustified Takedowns of Posts by and about
    Palestinians’, Electronic Frontier Foundation, 8 November 2023,
    https://
    www.eff.org/deeplinks/2023/11/platforms-must-stop-unjustifiedtakedowns-posts-and-about-palestinians
    (accessed 15 November 2023); ‘Digital Blackout: Systematic
    Censorship of Palestinian Voices’, Global Voices, 8 November 2023,
    https://globalvoices.org/2023/11/08/digital-blackout-systematic-censorship-of-palestinian-voices
    (accessed 15 November 2023); Kari Paul, ‘Instagram Users Accuse
    Platform of Censoring Posts Supporting Palestine’, *The Guardian*,
    18 October 2023, https://
    www.theguardian.com/technology/2023/oct/18/instagram-palestine-postscensorship-accusations
    (accessed 15 November 2023); Priyanka Shankar, Pranav Dixit, and
    Usaid Siddiqui, ‘Are Social Media Giants Censoring ProPalestine
    Voices Amid Israel’s War?’ Al Jazeera, 24 October 2023, https://
    www.aljazeera.com/features/2023/10/24/shadowbanning-are-social-mediagiants-censoring-pro-palestine-voices
    (accessed 15 November 2023).

14. Fricker, ‘Introduction’.

15. ‘How Zoom Violated Its Own Terms of Service for Access to China’s
    Market’, Human Rights Watch, 22 December 2020, https://www.hrw.org/
    news/2020/12/22/how-zoom-violated-its-own-terms-service-access-chinasmarket
    (accessed 17 April 2024).

16. Alice Speri and Sam Biddle, ‘Zoom Censorship of Palestine Seminars
    Sparks Fight over Academic Freedom’, *The Intercept*, 14 November
    2020, https://
    theintercept.com/2020/11/14/zoom-censorship-leila-khaled-palestine
    (accessed 29 June 2022).
